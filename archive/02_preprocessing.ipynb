{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4137e17f",
   "metadata": {},
   "source": [
    "# 02 - Preprocesamiento de Datos\n",
    "## Kaggle Playground Series S5E6: Predicting Optimal Fertilizers\n",
    "\n",
    "**Autor:** F√©lix  \n",
    "**Fecha:** 3 de junio de 2025  \n",
    "**Objetivo:** Preparar datos para modelos TIER 1 (Random Forest, LightGBM, XGBoost)\n",
    "\n",
    "### üìã Plan de Trabajo:\n",
    "1. **Recrear variables del EDA** - Todas las features identificadas como importantes\n",
    "2. **Encoding** - Preparar variables categ√≥ricas para los modelos\n",
    "3. **Escalado** - Normalizar variables num√©ricas \n",
    "4. **Divisi√≥n** - Train/Validation 80/20 con random_state=513\n",
    "5. **Guardado** - Datasets listos para modelado en `/data/processed/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecafd450",
   "metadata": {},
   "source": [
    "## üìö Importar Librer√≠as Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ddf99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directorio ya existe: ../data/processed\n",
      "Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Configuraciones\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(513)\n",
    "\n",
    "# Crear directorio para datos procesados si no existe\n",
    "processed_dir = '../data/processed'\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "    print(f\"‚úÖ Directorio creado: {processed_dir}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Directorio ya existe: {processed_dir}\")\n",
    "\n",
    "print(\"Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65a1ba",
   "metadata": {},
   "source": [
    "## üìä Cargar Datos de Entrenamiento y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da99288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMACI√ìN DE DATASETS ===\n",
      "\n",
      "üìà Train shape: (750000, 9)\n",
      "üìä Test shape: (250000, 8)\n",
      "üìù Sample submission shape: (250000, 2)\n",
      "\n",
      "=== COLUMNAS DISPONIBLES ===\n",
      "\n",
      "Train columns: ['Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'Fertilizer Name']\n",
      "Test columns: ['Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
      "\n",
      "=== VARIABLE OBJETIVO ===\n",
      "\n",
      "Tipos √∫nicos de fertilizantes: 7\n",
      "Distribuci√≥n target (top 5):\n",
      "Fertilizer Name\n",
      "14-35-14    114436\n",
      "10-26-26    113887\n",
      "17-17-17    112453\n",
      "28-28       111158\n",
      "20-20       110889\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== VERIFICACI√ìN DE CONSISTENCIA ===\n",
      "\n",
      "‚úÖ Train y test tienen las mismas features\n",
      "\n",
      "=== PREVIEW DE DATOS ===\n",
      "\n",
      "Train (con √≠ndice 'id'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Crop Type</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphorous</th>\n",
       "      <th>Fertilizer Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>Clayey</td>\n",
       "      <td>Sugarcane</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>28-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Millets</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>28-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Millets</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17-17-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temparature  Humidity  Moisture Soil Type  Crop Type  Nitrogen  Potassium  \\\n",
       "id                                                                              \n",
       "0            37        70        36    Clayey  Sugarcane        36          4   \n",
       "1            27        69        65     Sandy    Millets        30          6   \n",
       "2            29        63        32     Sandy    Millets        24         12   \n",
       "\n",
       "    Phosphorous Fertilizer Name  \n",
       "id                               \n",
       "0             5           28-28  \n",
       "1            18           28-28  \n",
       "2            16        17-17-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test (con √≠ndice 'id'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Crop Type</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphorous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750000</th>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>52</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750001</th>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>45</td>\n",
       "      <td>Red</td>\n",
       "      <td>Sugarcane</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750002</th>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>Clayey</td>\n",
       "      <td>Ground Nuts</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temparature  Humidity  Moisture Soil Type    Crop Type  Nitrogen  \\\n",
       "id                                                                         \n",
       "750000           31        70        52     Sandy        Wheat        34   \n",
       "750001           27        62        45       Red    Sugarcane        30   \n",
       "750002           28        72        28    Clayey  Ground Nuts        14   \n",
       "\n",
       "        Potassium  Phosphorous  \n",
       "id                              \n",
       "750000         11           24  \n",
       "750001         14           15  \n",
       "750002         15            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar datasets originales\n",
    "train_df = pd.read_csv('../data/train.csv').set_index('id')  # ‚Üê Establecer 'id' como √≠ndice\n",
    "test_df = pd.read_csv('../data/test.csv').set_index('id')   # ‚Üê Establecer 'id' como √≠ndice\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(\"=== INFORMACI√ìN DE DATASETS ===\\n\")\n",
    "print(f\"üìà Train shape: {train_df.shape}\")\n",
    "print(f\"üìä Test shape: {test_df.shape}\")\n",
    "print(f\"üìù Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "print(\"\\n=== COLUMNAS DISPONIBLES ===\\n\")\n",
    "print(f\"Train columns: {list(train_df.columns)}\")\n",
    "print(f\"Test columns: {list(test_df.columns)}\")\n",
    "\n",
    "print(\"\\n=== VARIABLE OBJETIVO ===\\n\")\n",
    "print(f\"Tipos √∫nicos de fertilizantes: {train_df['Fertilizer Name'].nunique()}\")\n",
    "print(f\"Distribuci√≥n target (top 5):\")\n",
    "print(train_df['Fertilizer Name'].value_counts().head())\n",
    "\n",
    "# Verificar consistencia entre train y test\n",
    "print(\"\\n=== VERIFICACI√ìN DE CONSISTENCIA ===\\n\")\n",
    "train_cols = set(train_df.columns) - {'Fertilizer Name'}\n",
    "test_cols = set(test_df.columns)  # test ya no tiene 'id' como columna (es el √≠ndice)\n",
    "\n",
    "if train_cols == test_cols:\n",
    "    print(\"‚úÖ Train y test tienen las mismas features\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Diferencias en columnas:\")\n",
    "    print(f\"  Solo en train: {train_cols - test_cols}\")\n",
    "    print(f\"  Solo en test: {test_cols - train_cols}\")\n",
    "\n",
    "print(\"\\n=== PREVIEW DE DATOS ===\\n\")\n",
    "print(\"Train (con √≠ndice 'id'):\")\n",
    "display(train_df.head(3))\n",
    "print(\"\\nTest (con √≠ndice 'id'):\")\n",
    "display(test_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e792d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Recrear Variables del EDA\n",
    "\n",
    "### üéØ Feature Engineering Estrat√©gico\n",
    "Recrearemos todas las variables importantes identificadas en el EDA:\n",
    "- **Ratios NPK** - Relaciones entre nutrientes principales\n",
    "- **√çndices ambientales** - Combinaciones de variables clim√°ticas\n",
    "- **Categorizaci√≥n inteligente** - Niveles de nutrientes y condiciones\n",
    "- **Interacciones** - Combinaciones suelo-cultivo\n",
    "- **Features de balance** - M√©tricas de equilibrio nutricional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332e7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Aplicando feature engineering a TRAIN...\n",
      "  1Ô∏è‚É£ Creando ratios de nutrientes...\n",
      "  2Ô∏è‚É£ Creando √≠ndices ambientales...\n",
      "  3Ô∏è‚É£ Creando categor√≠as basadas en distribuciones...\n",
      "  4Ô∏è‚É£ Creando interacciones estrat√©gicas...\n",
      "  5Ô∏è‚É£ Features de balance y ratios avanzados...\n",
      "  ‚úÖ 16 nuevas features creadas\n",
      "üîß Aplicando feature engineering a TEST...\n",
      "  1Ô∏è‚É£ Creando ratios de nutrientes...\n",
      "  2Ô∏è‚É£ Creando √≠ndices ambientales...\n",
      "  3Ô∏è‚É£ Creando categor√≠as basadas en distribuciones...\n",
      "  4Ô∏è‚É£ Creando interacciones estrat√©gicas...\n",
      "  5Ô∏è‚É£ Features de balance y ratios avanzados...\n",
      "  ‚úÖ 16 nuevas features creadas\n",
      "\n",
      "üìä RESUMEN DESPU√âS DEL FEATURE ENGINEERING:\n",
      "  ‚Ä¢ Train shape: (750000, 25)\n",
      "  ‚Ä¢ Test shape: (250000, 24)\n",
      "  ‚Ä¢ Nuevas features: 16\n",
      "  ‚Ä¢ Features categ√≥ricas nuevas: ['N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo', 'Dominant_NPK_Level']\n",
      "  ‚Ä¢ Features num√©ricas nuevas: ['N_P_ratio', 'N_K_ratio', 'P_K_ratio', 'Total_NPK', 'Temp_Hum_index', 'Moist_Balance', 'Environ_Stress', 'NPK_Balance', 'Dominant_NPK_Level', 'Temp_Moist_inter']\n"
     ]
    }
   ],
   "source": [
    "def apply_feature_engineering(df, is_train=True):\n",
    "    \"\"\"\n",
    "    Aplica el mismo feature engineering del EDA a cualquier dataset\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    print(f\"üîß Aplicando feature engineering a {'TRAIN' if is_train else 'TEST'}...\")\n",
    "    \n",
    "    # 1. RATIOS DE NUTRIENTES (basado en alto MI de NPK)\n",
    "    print(\"  1Ô∏è‚É£ Creando ratios de nutrientes...\")\n",
    "    df_features[\"N_P_ratio\"] = df_features[\"Nitrogen\"] / (df_features[\"Phosphorous\"] + 1)\n",
    "    df_features[\"N_K_ratio\"] = df_features[\"Nitrogen\"] / (df_features[\"Potassium\"] + 1)\n",
    "    df_features[\"P_K_ratio\"] = df_features[\"Phosphorous\"] / (df_features[\"Potassium\"] + 1)\n",
    "    df_features[\"Total_NPK\"] = (\n",
    "        df_features[\"Nitrogen\"] + df_features[\"Phosphorous\"] + df_features[\"Potassium\"]\n",
    "    )\n",
    "    \n",
    "    # 2. √çNDICES AMBIENTALES\n",
    "    print(\"  2Ô∏è‚É£ Creando √≠ndices ambientales...\")\n",
    "    df_features[\"Temp_Hum_index\"] = (\n",
    "        df_features[\"Temparature\"] * df_features[\"Humidity\"] / 100\n",
    "    )\n",
    "    df_features[\"Moist_Balance\"] = df_features[\"Moisture\"] - df_features[\"Humidity\"]\n",
    "    df_features[\"Environ_Stress\"] = abs(df_features[\"Temparature\"] - 25) + abs(\n",
    "        df_features[\"Humidity\"] - 65\n",
    "    )\n",
    "    \n",
    "    # 3. CATEGORIZACI√ìN INTELIGENTE\n",
    "    print(\"  3Ô∏è‚É£ Creando categor√≠as basadas en distribuciones...\")\n",
    "    df_features[\"Temp_Cat\"] = pd.cut(\n",
    "        df_features[\"Temparature\"],\n",
    "        bins=[0, 25, 30, 35, 100],\n",
    "        labels=[\"Fr√≠o\", \"Templado\", \"C√°lido\", \"Muy_C√°lido\"],\n",
    "    )\n",
    "    df_features[\"Hum_Cat\"] = pd.cut(\n",
    "        df_features[\"Humidity\"],\n",
    "        bins=[0, 50, 65, 80, 100],\n",
    "        labels=[\"Muy_Baja\", \"Baja\", \"Media\", \"Alta\"],\n",
    "    )\n",
    "    df_features[\"N_Level\"] = pd.cut(\n",
    "        df_features[\"Nitrogen\"], bins=[0, 15, 25,100], include_lowest=True,  labels=[\"Bajo\", \"Medio\", \"Alto\"]\n",
    "    )\n",
    "    df_features[\"K_Level\"] = pd.cut(\n",
    "        df_features[\"Potassium\"], bins=[0, 4, 14, 100],  include_lowest=True, labels=[\"Bajo\", \"Medio\", \"Alto\"]\n",
    "    )\n",
    "    df_features[\"P_Level\"] = pd.cut(\n",
    "        df_features[\"Phosphorous\"], bins=[0, 10, 32,100], include_lowest=True,  labels=[\"Bajo\", \"Medio\", \"Alto\"]\n",
    "    )\n",
    "    \n",
    "    # 4. FEATURES DE INTERACCI√ìN\n",
    "    print(\"  4Ô∏è‚É£ Creando interacciones estrat√©gicas...\")\n",
    "    df_features[\"Soil_Crop_Combo\"] = (\n",
    "        df_features[\"Soil Type\"] + \"_\" + df_features[\"Crop Type\"]\n",
    "    )\n",
    "    \n",
    "    # 5. FEATURES DE BALANCE Y RATIOS AVANZADOS\n",
    "    print(\"  5Ô∏è‚É£ Features de balance y ratios avanzados...\")\n",
    "    \n",
    "    # Balance de macronutrientes\n",
    "    df_features['NPK_Balance'] = abs(df_features['Nitrogen'] - df_features['Phosphorous']) + \\\n",
    "                                abs(df_features['Nitrogen'] - df_features['Potassium']) + \\\n",
    "                                abs(df_features['Phosphorous'] - df_features['Potassium'])\n",
    "    \n",
    "    # √çndice de nutriente dominante\n",
    "    max_nutrient = df_features[['Nitrogen', 'Phosphorous', 'Potassium']].max(axis=1)\n",
    "    df_features['Dominant_NPK_Level'] = max_nutrient\n",
    "    \n",
    "    # Condiciones ambientales combinadas\n",
    "    df_features['Temp_Moist_inter'] = df_features['Temparature'] * df_features['Moisture'] / 100\n",
    "    \n",
    "    # Listar nuevas features creadas\n",
    "    new_features = [\n",
    "        \"N_P_ratio\", \"N_K_ratio\", \"P_K_ratio\", \"Total_NPK\",\n",
    "        \"Temp_Hum_index\", \"Moist_Balance\", \"Environ_Stress\",\n",
    "        \"Temp_Cat\", \"Hum_Cat\", \"N_Level\", \"K_Level\", \"P_Level\",\n",
    "        \"Soil_Crop_Combo\", 'NPK_Balance', 'Dominant_NPK_Level', 'Temp_Moist_inter'\n",
    "    ]\n",
    "    \n",
    "    print(f\"  ‚úÖ {len(new_features)} nuevas features creadas\")\n",
    "    \n",
    "    return df_features, new_features\n",
    "\n",
    "# Aplicar feature engineering a ambos datasets\n",
    "train_processed, new_features_list = apply_feature_engineering(train_df, is_train=True)\n",
    "test_processed, _ = apply_feature_engineering(test_df, is_train=False)\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DESPU√âS DEL FEATURE ENGINEERING:\")\n",
    "print(f\"  ‚Ä¢ Train shape: {train_processed.shape}\")\n",
    "print(f\"  ‚Ä¢ Test shape: {test_processed.shape}\")\n",
    "print(f\"  ‚Ä¢ Nuevas features: {len(new_features_list)}\")\n",
    "print(f\"  ‚Ä¢ Features categ√≥ricas nuevas: {[f for f in new_features_list if 'Category' in f or 'Level' in f or 'Combo' in f]}\")\n",
    "print(f\"  ‚Ä¢ Features num√©ricas nuevas: {[f for f in new_features_list if f not in ['Temp_Cat', 'Hum_Cat', 'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2cd91",
   "metadata": {},
   "source": [
    "## üî¢ Codificaci√≥n de Variables Categ√≥ricas\n",
    "\n",
    "### üéØ Estrategia de Encoding por Modelo:\n",
    "- **Random Forest**: Puede manejar categ√≥ricas directamente, pero usaremos Label Encoding\n",
    "- **LightGBM**: Nativo con categ√≥ricas, pero Label Encoding es m√°s estable\n",
    "- **XGBoost**: Requiere encoding num√©rico - usaremos Label Encoding\n",
    "\n",
    "**Decisi√≥n**: Usar **Label Encoding** para todas las categ√≥ricas para m√°xima compatibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f6a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Aplicando Label Encoding...\n",
      "\n",
      "Variables categ√≥ricas a codificar: ['Soil Type', 'Crop Type', 'Temp_Cat', 'Hum_Cat', 'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo']\n",
      "  ‚Ä¢ Soil Type:\n",
      "    Total categor√≠as: 5\n",
      "  ‚Ä¢ Crop Type:\n",
      "    Total categor√≠as: 11\n",
      "  ‚Ä¢ Temp_Cat:\n",
      "    Total categor√≠as: 4\n",
      "  ‚Ä¢ Hum_Cat:\n",
      "    Total categor√≠as: 3\n",
      "  ‚Ä¢ N_Level:\n",
      "    Total categor√≠as: 3\n",
      "  ‚Ä¢ K_Level:\n",
      "    Total categor√≠as: 3\n",
      "  ‚Ä¢ P_Level:\n",
      "    Total categor√≠as: 3\n",
      "  ‚Ä¢ Soil_Crop_Combo:\n",
      "    Total categor√≠as: 55\n",
      "\n",
      "üéØ Codificando variable objetivo: Fertilizer Name\n",
      "    Total clases objetivo: 7\n",
      "    Ejemplos: {'10-26-26': 0, '14-35-14': 1, '17-17-17': 2, '20-20': 3, '28-28': 4}\n",
      "    ‚úÖ Objetivo solo en train (correcto para competici√≥n Kaggle)\n",
      "\n",
      "üìä RESUMEN DESPU√âS DEL ENCODING:\n",
      "  ‚Ä¢ Train shape: (750000, 34)\n",
      "  ‚Ä¢ Test shape: (250000, 32)\n",
      "  ‚Ä¢ Encoders creados: 9\n",
      "  ‚Ä¢ Variables codificadas: ['Soil Type', 'Crop Type', 'Temp_Cat', 'Hum_Cat', 'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo', 'Fertilizer Name']\n",
      "\n",
      "üìà COLUMNAS PARA ESCALADO:\n",
      "  ‚Ä¢ Originales: ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
      "  ‚Ä¢ Nuevas num√©ricas: ['N_P_ratio', 'N_K_ratio', 'P_K_ratio', 'Total_NPK', 'Temp_Hum_index', 'Moist_Balance', 'Environ_Stress', 'NPK_Balance', 'Dominant_NPK_Level', 'Temp_Moist_inter']\n",
      "  ‚Ä¢ Codificadas: ['Soil Type_encoded', 'Crop Type_encoded', 'Temp_Cat_encoded', 'Hum_Cat_encoded', 'N_Level_encoded', 'K_Level_encoded', 'P_Level_encoded', 'Soil_Crop_Combo_encoded', 'Fertilizer Name_encoded']\n",
      "  ‚Ä¢ Total para escalado: 25\n"
     ]
    }
   ],
   "source": [
    "def apply_encoding(train_df, test_df, target_col='Fertilizer Name'):\n",
    "    \"\"\"\n",
    "    Aplica Label Encoding a todas las variables categ√≥ricas\n",
    "    Mantiene consistencia entre train y test\n",
    "    Maneja correctamente el caso donde test no tiene columna objetivo (competici√≥n Kaggle)\n",
    "    \"\"\"\n",
    "    print(\"üî¢ Aplicando Label Encoding...\\n\")\n",
    "    \n",
    "    # Identificar variables categ√≥ricas\n",
    "    categorical_cols = [\n",
    "        'Soil Type', 'Crop Type', 'Temp_Cat', 'Hum_Cat', \n",
    "        'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo'\n",
    "    ]\n",
    "    \n",
    "    # Verificar que existan en ambos datasets (excluyendo target)\n",
    "    existing_categorical = [col for col in categorical_cols if col in train_df.columns and col in test_df.columns]\n",
    "    \n",
    "    print(f\"Variables categ√≥ricas a codificar: {existing_categorical}\")\n",
    "    \n",
    "    # Copiar datasets\n",
    "    train_encoded = train_df.copy()\n",
    "    test_encoded = test_df.copy()\n",
    "    \n",
    "    # Diccionario para almacenar encoders\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Aplicar Label Encoding a features (no target)\n",
    "    for col in existing_categorical:\n",
    "        print(f\"  ‚Ä¢ {col}:\")\n",
    "        \n",
    "        # Crear encoder\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        # Combinar valores √∫nicos de train y test para consistencia\n",
    "        combined_values = pd.concat([train_df[col], test_df[col]]).astype(str)\n",
    "        le.fit(combined_values)\n",
    "        \n",
    "        # Aplicar encoding\n",
    "        train_encoded[f'{col}_encoded'] = le.transform(train_df[col].astype(str))\n",
    "        test_encoded[f'{col}_encoded'] = le.transform(test_df[col].astype(str))\n",
    "        \n",
    "        # Guardar encoder\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        # Mostrar mapeo (primeros 5)\n",
    "        unique_values = train_df[col].unique()[:5]\n",
    "        print(f\"    Total categor√≠as: {len(le.classes_)}\")\n",
    "    \n",
    "    # Codificar variable objetivo (solo para train - no existe en test)\n",
    "    if target_col in train_encoded.columns:\n",
    "        print(f\"\\nüéØ Codificando variable objetivo: {target_col}\")\n",
    "        target_encoder = LabelEncoder()\n",
    "        train_encoded[f'{target_col}_encoded'] = target_encoder.fit_transform(train_encoded[target_col])\n",
    "        label_encoders[target_col] = target_encoder\n",
    "        print(f\"    Total clases objetivo: {len(target_encoder.classes_)}\")\n",
    "        print(f\"    Ejemplos: {dict(list(zip(target_encoder.classes_[:5], range(5))))}\")\n",
    "        print(f\"    ‚úÖ Objetivo solo en train (correcto para competici√≥n Kaggle)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Variable objetivo '{target_col}' no encontrada en train\")\n",
    "    \n",
    "    return train_encoded, test_encoded, label_encoders\n",
    "\n",
    "# Aplicar encoding\n",
    "train_encoded, test_encoded, encoders_dict = apply_encoding(train_processed, test_processed)\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DESPU√âS DEL ENCODING:\")\n",
    "print(f\"  ‚Ä¢ Train shape: {train_encoded.shape}\")\n",
    "print(f\"  ‚Ä¢ Test shape: {test_encoded.shape}\")\n",
    "print(f\"  ‚Ä¢ Encoders creados: {len(encoders_dict)}\")\n",
    "print(f\"  ‚Ä¢ Variables codificadas: {list(encoders_dict.keys())}\")\n",
    "\n",
    "# Identificar todas las columnas num√©ricas para escalado\n",
    "numeric_cols_original = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "numeric_cols_new = [col for col in new_features_list if col not in ['Temp_Cat', 'Hum_Cat', 'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo']]\n",
    "encoded_cols = [col for col in train_encoded.columns if col.endswith('_encoded')]\n",
    "\n",
    "all_numeric_cols = numeric_cols_original + numeric_cols_new + encoded_cols\n",
    "\n",
    "print(f\"\\nüìà COLUMNAS PARA ESCALADO:\")\n",
    "print(f\"  ‚Ä¢ Originales: {numeric_cols_original}\")\n",
    "print(f\"  ‚Ä¢ Nuevas num√©ricas: {numeric_cols_new}\")\n",
    "print(f\"  ‚Ä¢ Codificadas: {encoded_cols}\")\n",
    "print(f\"  ‚Ä¢ Total para escalado: {len(all_numeric_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1179be",
   "metadata": {},
   "source": [
    "## üìè Escalado de Datos\n",
    "\n",
    "### üéØ Estrategia de Escalado:\n",
    "- **StandardScaler**: Para variables con distribuciones normales\n",
    "- **Solo features comunes**: Train y test deben tener las mismas columnas\n",
    "- **Excluir variable objetivo**: Solo existe en train (competici√≥n Kaggle)\n",
    "- **Consistencia train/test**: Ajustar scaler solo en train, aplicar a test\n",
    "\n",
    "> **Nota**: Aunque Random Forest y XGBoost no requieren escalado, lo aplicamos para:\n",
    "> - Facilitar comparaciones entre modelos\n",
    "> - Mejorar convergencia de algunos algoritmos\n",
    "> - Mantener consistencia en el pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36eafa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DIAGN√ìSTICO PRE-ESCALADO:\n",
      "\n",
      "üìä COLUMNAS EN TRAIN (34):\n",
      "  Primeras 10: ['Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'Fertilizer Name', 'N_P_ratio']\n",
      "  √öltimas 10: ['Temp_Moist_inter', 'Soil Type_encoded', 'Crop Type_encoded', 'Temp_Cat_encoded', 'Hum_Cat_encoded', 'N_Level_encoded', 'K_Level_encoded', 'P_Level_encoded', 'Soil_Crop_Combo_encoded', 'Fertilizer Name_encoded']\n",
      "\n",
      "üìä COLUMNAS EN TEST (32):\n",
      "  Primeras 10: ['Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'N_P_ratio', 'N_K_ratio']\n",
      "  √öltimas 10: ['Dominant_NPK_Level', 'Temp_Moist_inter', 'Soil Type_encoded', 'Crop Type_encoded', 'Temp_Cat_encoded', 'Hum_Cat_encoded', 'N_Level_encoded', 'K_Level_encoded', 'P_Level_encoded', 'Soil_Crop_Combo_encoded']\n",
      "\n",
      "üîç AN√ÅLISIS DE COLUMNAS:\n",
      "  ‚Ä¢ Solo en train: 2 - ['Fertilizer Name_encoded', 'Fertilizer Name']\n",
      "  ‚Ä¢ Solo en test: 0 - []\n",
      "  ‚Ä¢ Comunes: 32\n",
      "\n",
      "üìà VERIFICACI√ìN DE COLUMNAS PARA ESCALADO:\n",
      "  ‚Ä¢ all_numeric_cols definidas: 25\n",
      "  ‚Ä¢ Muestra: ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous', 'N_P_ratio', 'N_K_ratio', 'P_K_ratio', 'Total_NPK']\n",
      "  ‚Ä¢ Existen en train: 25\n",
      "  ‚Ä¢ Existen en test: 24\n",
      "  ‚Ä¢ Existen en ambos: 24\n",
      "  ‚úÖ Variable objetivo NO en lista de features comunes (correcto)\n",
      "\n",
      "‚úÖ Diagn√≥stico completado - procediendo con escalado...\n"
     ]
    }
   ],
   "source": [
    "# üîç DIAGN√ìSTICO: Verificar columnas antes del escalado\n",
    "print(\"üîç DIAGN√ìSTICO PRE-ESCALADO:\\n\")\n",
    "\n",
    "print(f\"üìä COLUMNAS EN TRAIN ({len(train_encoded.columns)}):\")\n",
    "print(f\"  Primeras 10: {list(train_encoded.columns[:10])}\")\n",
    "print(f\"  √öltimas 10: {list(train_encoded.columns[-10:])}\")\n",
    "\n",
    "print(f\"\\nüìä COLUMNAS EN TEST ({len(test_encoded.columns)}):\")\n",
    "print(f\"  Primeras 10: {list(test_encoded.columns[:10])}\")\n",
    "print(f\"  √öltimas 10: {list(test_encoded.columns[-10:])}\")\n",
    "\n",
    "# Verificar diferencias cr√≠ticas\n",
    "train_only = set(train_encoded.columns) - set(test_encoded.columns)\n",
    "test_only = set(test_encoded.columns) - set(train_encoded.columns)\n",
    "common_cols = set(train_encoded.columns) & set(test_encoded.columns)\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE COLUMNAS:\")\n",
    "print(f\"  ‚Ä¢ Solo en train: {len(train_only)} - {list(train_only)}\")\n",
    "print(f\"  ‚Ä¢ Solo en test: {len(test_only)} - {list(test_only)}\")\n",
    "print(f\"  ‚Ä¢ Comunes: {len(common_cols)}\")\n",
    "\n",
    "# Verificar columnas para escalado\n",
    "print(f\"\\nüìà VERIFICACI√ìN DE COLUMNAS PARA ESCALADO:\")\n",
    "print(f\"  ‚Ä¢ all_numeric_cols definidas: {len(all_numeric_cols)}\")\n",
    "print(f\"  ‚Ä¢ Muestra: {all_numeric_cols[:10]}\")\n",
    "\n",
    "# Verificar cu√°les existen realmente\n",
    "existing_in_train = [col for col in all_numeric_cols if col in train_encoded.columns]\n",
    "existing_in_test = [col for col in all_numeric_cols if col in test_encoded.columns]\n",
    "existing_in_both = [col for col in all_numeric_cols if col in train_encoded.columns and col in test_encoded.columns]\n",
    "\n",
    "print(f\"  ‚Ä¢ Existen en train: {len(existing_in_train)}\")\n",
    "print(f\"  ‚Ä¢ Existen en test: {len(existing_in_test)}\")\n",
    "print(f\"  ‚Ä¢ Existen en ambos: {len(existing_in_both)}\")\n",
    "\n",
    "if 'Fertilizer Name_encoded' in existing_in_both:\n",
    "    print(f\"  ‚ö†Ô∏è  Variable objetivo en lista de features para escalado\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Variable objetivo NO en lista de features comunes (correcto)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Diagn√≥stico completado - procediendo con escalado...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84976426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Aplicando escalado con StandardScaler...\n",
      "\n",
      "Columnas a escalar: 24\n",
      "Muestra: ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous', 'N_P_ratio', 'N_K_ratio', 'P_K_ratio', 'Total_NPK']...\n",
      "‚úÖ Correcto: Variable objetivo 'Fertilizer Name_encoded' solo en train (competici√≥n Kaggle)\n",
      "‚úÖ Escalado aplicado exitosamente\n",
      "\n",
      "üìä ESTAD√çSTICAS POST-ESCALADO:\n",
      "  ‚Ä¢ Media de features escaladas (train): -0.000\n",
      "  ‚Ä¢ Std de features escaladas (train): 1.000\n",
      "  ‚Ä¢ Rango medio escalado: [-2.82, 8.92]\n",
      "\n",
      "üéØ DATASETS FINALES PREPARADOS:\n",
      "  ‚Ä¢ Train shape: (750000, 34)\n",
      "  ‚Ä¢ Test shape: (250000, 32)\n",
      "  ‚Ä¢ Features num√©ricas escaladas: 24\n",
      "  ‚Ä¢ Variable objetivo disponible: True\n",
      "\n",
      "üîç VERIFICACI√ìN DE CALIDAD:\n",
      "  ‚Ä¢ Nulos en train: 0\n",
      "  ‚Ä¢ Nulos en test: 0\n",
      "  ‚Ä¢ Infinitos en train: 0\n",
      "  ‚Ä¢ Infinitos en test: 0\n",
      "  ‚úÖ Datasets limpios - sin valores nulos o infinitos\n"
     ]
    }
   ],
   "source": [
    "def apply_scaling(train_df, test_df, numeric_columns, target_col='Fertilizer Name_encoded'):\n",
    "    \"\"\"\n",
    "    Aplica StandardScaler a las columnas num√©ricas\n",
    "    Mantiene separados los features de la variable objetivo\n",
    "    Maneja correctamente el caso donde test no tiene columna objetivo (competici√≥n Kaggle)\n",
    "    \"\"\"\n",
    "    print(\"üìè Aplicando escalado con StandardScaler...\\n\")\n",
    "    \n",
    "    # Copiar datasets\n",
    "    train_scaled = train_df.copy()\n",
    "    test_scaled = test_df.copy()\n",
    "    \n",
    "    # Filtrar columnas que realmente existen en AMBOS datasets\n",
    "    # Excluir columna objetivo de las features a escalar\n",
    "    existing_numeric_train = [col for col in numeric_columns if col in train_df.columns and col != target_col]\n",
    "    existing_numeric_test = [col for col in numeric_columns if col in test_df.columns]\n",
    "    \n",
    "    # Solo escalar columnas que existen en ambos datasets\n",
    "    existing_numeric = [col for col in existing_numeric_train if col in existing_numeric_test]\n",
    "    \n",
    "    print(f\"Columnas a escalar: {len(existing_numeric)}\")\n",
    "    print(f\"Muestra: {existing_numeric[:10]}...\")\n",
    "    \n",
    "    if target_col in train_df.columns and target_col not in test_df.columns:\n",
    "        print(f\"‚úÖ Correcto: Variable objetivo '{target_col}' solo en train (competici√≥n Kaggle)\")\n",
    "    \n",
    "    # Crear y ajustar scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Ajustar solo en train con las features comunes\n",
    "    train_features = train_df[existing_numeric]\n",
    "    scaler.fit(train_features)\n",
    "    \n",
    "    # Aplicar escalado\n",
    "    train_scaled_features = scaler.transform(train_features)\n",
    "    test_scaled_features = scaler.transform(test_df[existing_numeric])\n",
    "    \n",
    "    # Reemplazar en los DataFrames\n",
    "    train_scaled[existing_numeric] = train_scaled_features\n",
    "    test_scaled[existing_numeric] = test_scaled_features\n",
    "    \n",
    "    print(f\"‚úÖ Escalado aplicado exitosamente\")\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS POST-ESCALADO:\")\n",
    "    print(f\"  ‚Ä¢ Media de features escaladas (train): {train_scaled[existing_numeric].mean().mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ Std de features escaladas (train): {train_scaled[existing_numeric].std().mean():.3f}\")\n",
    "    print(f\"  ‚Ä¢ Rango medio escalado: [{train_scaled[existing_numeric].min().min():.2f}, {train_scaled[existing_numeric].max().max():.2f}]\")\n",
    "    \n",
    "    return train_scaled, test_scaled, scaler, existing_numeric\n",
    "\n",
    "# Aplicar escalado\n",
    "train_final, test_final, scaler_fitted, numeric_cols_used = apply_scaling(\n",
    "    train_encoded, test_encoded, all_numeric_cols\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ DATASETS FINALES PREPARADOS:\")\n",
    "print(f\"  ‚Ä¢ Train shape: {train_final.shape}\")\n",
    "print(f\"  ‚Ä¢ Test shape: {test_final.shape}\")\n",
    "print(f\"  ‚Ä¢ Features num√©ricas escaladas: {len(numeric_cols_used)}\")\n",
    "print(f\"  ‚Ä¢ Variable objetivo disponible: {'Fertilizer Name_encoded' in train_final.columns}\")\n",
    "\n",
    "# Verificar que no hay valores nulos despu√©s del procesamiento\n",
    "print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD:\")\n",
    "print(f\"  ‚Ä¢ Nulos en train: {train_final.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Nulos en test: {test_final.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Infinitos en train: {np.isinf(train_final.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Infinitos en test: {np.isinf(test_final.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "if train_final.isnull().sum().sum() == 0 and test_final.isnull().sum().sum() == 0:\n",
    "    print(\"  ‚úÖ Datasets limpios - sin valores nulos o infinitos\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Revisar valores nulos o infinitos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5facb",
   "metadata": {},
   "source": [
    "## üîÑ Divisi√≥n en Conjuntos de Entrenamiento y Validaci√≥n\n",
    "\n",
    "### üéØ Configuraci√≥n de Divisi√≥n:\n",
    "- **Proporci√≥n**: 80% entrenamiento, 20% validaci√≥n\n",
    "- **Random State**: 513 (para reproducibilidad)\n",
    "- **Estratificada**: Por tipo de fertilizante (variable objetivo)\n",
    "- **Separaci√≥n**: X (features) e y (target) claramente definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7f99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creando divisi√≥n train/validation...\n",
      "\n",
      "üìä CONFIGURACI√ìN DE DIVISI√ìN:\n",
      "  ‚Ä¢ Total muestras: 750,000\n",
      "  ‚Ä¢ Features: 32\n",
      "  ‚Ä¢ Clases objetivo: 7\n",
      "  ‚Ä¢ Proporci√≥n validaci√≥n: 20.0%\n",
      "  ‚Ä¢ Random state: 513\n",
      "\n",
      "‚úÖ DIVISI√ìN COMPLETADA:\n",
      "  ‚Ä¢ Train: 600,000 muestras (80.0%)\n",
      "  ‚Ä¢ Validation: 150,000 muestras (20.0%)\n",
      "\n",
      "üìä VERIFICACI√ìN ESTRATIFICACI√ìN:\n",
      "  ‚Ä¢ Diferencia m√°xima en distribuci√≥n: 0.0000\n",
      "  ‚úÖ Estratificaci√≥n exitosa (diferencia < 1%)\n",
      "\n",
      "üéØ DATASETS FINALES PARA MODELADO:\n",
      "  ‚Ä¢ X_train: (600000, 32)\n",
      "  ‚Ä¢ X_val: (150000, 32)\n",
      "  ‚Ä¢ y_train: (600000,) (clases √∫nicas: 7)\n",
      "  ‚Ä¢ y_val: (150000,) (clases √∫nicas: 7)\n",
      "  ‚Ä¢ Test completo: (250000, 32)\n",
      "\n",
      "üìã RESUMEN DE FEATURES:\n",
      "  ‚Ä¢ Total features: 32\n",
      "  ‚Ä¢ Features originales: 6\n",
      "  ‚Ä¢ Features nuevas: 24\n",
      "  ‚Ä¢ Todas escaladas: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "def create_train_validation_split(df, target_col='Fertilizer Name_encoded', test_size=0.2, random_state=513):\n",
    "    \"\"\"\n",
    "    Crea divisi√≥n estratificada de entrenamiento y validaci√≥n\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Creando divisi√≥n train/validation...\\n\")\n",
    "    \n",
    "    # Definir features y target\n",
    "    feature_cols = [col for col in df.columns if col not in [target_col, 'Fertilizer Name']]\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    print(f\"üìä CONFIGURACI√ìN DE DIVISI√ìN:\")\n",
    "    print(f\"  ‚Ä¢ Total muestras: {len(df):,}\")\n",
    "    print(f\"  ‚Ä¢ Features: {len(feature_cols)}\")\n",
    "    print(f\"  ‚Ä¢ Clases objetivo: {y.nunique()}\")\n",
    "    print(f\"  ‚Ä¢ Proporci√≥n validaci√≥n: {test_size*100}%\")\n",
    "    print(f\"  ‚Ä¢ Random state: {random_state}\")\n",
    "    \n",
    "    # Divisi√≥n estratificada\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ DIVISI√ìN COMPLETADA:\")\n",
    "    print(f\"  ‚Ä¢ Train: {len(X_train):,} muestras ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Validation: {len(X_val):,} muestras ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Verificar distribuci√≥n estratificada\n",
    "    train_dist = y_train.value_counts(normalize=True).sort_index()\n",
    "    val_dist = y_val.value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    print(f\"\\nüìä VERIFICACI√ìN ESTRATIFICACI√ìN:\")\n",
    "    print(f\"  ‚Ä¢ Diferencia m√°xima en distribuci√≥n: {abs(train_dist - val_dist).max():.4f}\")\n",
    "    if abs(train_dist - val_dist).max() < 0.01:\n",
    "        print(f\"  ‚úÖ Estratificaci√≥n exitosa (diferencia < 1%)\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Verificar estratificaci√≥n\")\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val, feature_cols\n",
    "\n",
    "# Crear divisi√≥n\n",
    "X_train, X_val, y_train, y_val, feature_columns = create_train_validation_split(train_final)\n",
    "\n",
    "print(f\"\\nüéØ DATASETS FINALES PARA MODELADO:\")\n",
    "print(f\"  ‚Ä¢ X_train: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_val: {X_val.shape}\")\n",
    "print(f\"  ‚Ä¢ y_train: {y_train.shape} (clases √∫nicas: {y_train.nunique()})\")\n",
    "print(f\"  ‚Ä¢ y_val: {y_val.shape} (clases √∫nicas: {y_val.nunique()})\")\n",
    "print(f\"  ‚Ä¢ Test completo: {test_final[feature_columns].shape}\")\n",
    "\n",
    "# Preparar dataset de test para predicci√≥n\n",
    "X_test = test_final[feature_columns]\n",
    "\n",
    "print(f\"\\nüìã RESUMEN DE FEATURES:\")\n",
    "print(f\"  ‚Ä¢ Total features: {len(feature_columns)}\")\n",
    "print(f\"  ‚Ä¢ Features originales: {len(numeric_cols_original)}\")\n",
    "print(f\"  ‚Ä¢ Features nuevas: {len([f for f in feature_columns if f in new_features_list or f.endswith('_encoded')])}\")\n",
    "print(f\"  ‚Ä¢ Todas escaladas: ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ab7b4",
   "metadata": {},
   "source": [
    "## üíæ Guardar Datasets Procesados\n",
    "\n",
    "### üéØ Estructura de Archivos:\n",
    "- **Datos principales**: X_train, X_val, y_train, y_val, X_test (formato .parquet)\n",
    "- **Metadatos**: encoders, scaler, mapeos de columnas (.pkl)\n",
    "- **Datasets completos**: train/test procesados con √≠ndice 'id' (.parquet)\n",
    "\n",
    "### üì¶ Ventajas del formato .parquet:\n",
    "- **Eficiencia**: Archivos 60-80% m√°s peque√±os que CSV\n",
    "- **Velocidad**: Carga/escritura m√°s r√°pida\n",
    "- **Tipos preservados**: Mantiene autom√°ticamente dtypes e √≠ndices\n",
    "- **Compatibilidad**: Funciona con pandas, sklearn y todos los frameworks ML\n",
    "\n",
    "### üìÅ Ubicaci√≥n: `/data/processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b326ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Guardando datasets procesados (formato .parquet optimizado)...\n",
      "\n",
      "1Ô∏è‚É£ Guardando datasets de entrenamiento y validaci√≥n...\n",
      "  ‚úÖ X_train.parquet: (600000, 32)\n",
      "  ‚úÖ X_val.parquet: (150000, 32)\n",
      "  ‚úÖ y_train.parquet: (600000,)\n",
      "  ‚úÖ y_val.parquet: (150000,)\n",
      "  ‚úÖ X_test.parquet: (250000, 32)\n",
      "\n",
      "2Ô∏è‚É£ Guardando metadatos y configuraciones...\n",
      "  ‚úÖ label_encoders.pkl: 9 encoders\n",
      "  ‚úÖ standard_scaler.pkl: scaler para 24 features\n",
      "  ‚úÖ feature_info.pkl: informaci√≥n de 32 features\n",
      "\n",
      "3Ô∏è‚É£ Guardando datasets completos con √≠ndice 'id'...\n",
      "  ‚úÖ train_complete_processed.parquet: (750000, 34) (con √≠ndice 'id')\n",
      "  ‚úÖ test_complete_processed.parquet: (250000, 32) (con √≠ndice 'id')\n",
      "\n",
      "üéâ Todos los datasets guardados exitosamente\n",
      "\n",
      "üéâ ¬°PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\n",
      "\n",
      "üìÅ ARCHIVOS GUARDADOS EN: ../data/processed\n",
      "\n",
      "üìä RESUMEN FINAL:\n",
      "  ‚Ä¢ Datasets listos para: Random Forest, LightGBM, XGBoost\n",
      "  ‚Ä¢ Features totales: 32\n",
      "  ‚Ä¢ Train/Validation: 80/20 estratificado\n",
      "  ‚Ä¢ Random state: 513\n",
      "  ‚Ä¢ Escalado: StandardScaler aplicado\n",
      "  ‚Ä¢ Encoding: Label Encoding para categ√≥ricas\n",
      "\n",
      "üöÄ PR√ìXIMOS PASOS:\n",
      "  1. Cargar datasets desde /data/processed/\n",
      "  2. Implementar modelos TIER 1\n",
      "  3. Evaluar performance con validation set\n",
      "  4. Generar predicciones para submission\n",
      "\n",
      "‚úÖ ¬°Listos para modelado!\n"
     ]
    }
   ],
   "source": [
    "def save_processed_datasets():\n",
    "    \"\"\"\n",
    "    Guarda todos los datasets procesados y metadatos necesarios\n",
    "    OPTIMIZADO: Usando formato .parquet (m√°s eficiente, mantiene √≠ndices y tipos autom√°ticamente)\n",
    "    No crea archivos redundantes ya que la informaci√≥n de ID est√° en el √≠ndice del dataset\n",
    "    \"\"\"\n",
    "    print(\"üíæ Guardando datasets procesados (formato .parquet optimizado)...\\n\")\n",
    "    \n",
    "    # 1. DATASETS PRINCIPALES\n",
    "    print(\"1Ô∏è‚É£ Guardando datasets de entrenamiento y validaci√≥n...\")\n",
    "    \n",
    "    # Datasets de entrenamiento (DataFrames)\n",
    "    X_train.to_parquet(f'{processed_dir}/X_train.parquet')\n",
    "    X_val.to_parquet(f'{processed_dir}/X_val.parquet')\n",
    "    \n",
    "    # Variables objetivo (Series) - convertir a DataFrame para guardar en parquet\n",
    "    y_train.to_frame().to_parquet(f'{processed_dir}/y_train.parquet')\n",
    "    y_val.to_frame().to_parquet(f'{processed_dir}/y_val.parquet')\n",
    "    \n",
    "    # Dataset de test\n",
    "    X_test.to_parquet(f'{processed_dir}/X_test.parquet')\n",
    "    \n",
    "    print(f\"  ‚úÖ X_train.parquet: {X_train.shape}\")\n",
    "    print(f\"  ‚úÖ X_val.parquet: {X_val.shape}\")\n",
    "    print(f\"  ‚úÖ y_train.parquet: {y_train.shape}\")\n",
    "    print(f\"  ‚úÖ y_val.parquet: {y_val.shape}\")\n",
    "    print(f\"  ‚úÖ X_test.parquet: {X_test.shape}\")\n",
    "    \n",
    "    # 2. METADATOS Y CONFIGURACIONES\n",
    "    print(\"\\n2Ô∏è‚É£ Guardando metadatos y configuraciones...\")\n",
    "    \n",
    "    # Guardar encoders y scaler\n",
    "    joblib.dump(encoders_dict, f'{processed_dir}/label_encoders.pkl')\n",
    "    joblib.dump(scaler_fitted, f'{processed_dir}/standard_scaler.pkl')\n",
    "    print(f\"  ‚úÖ label_encoders.pkl: {len(encoders_dict)} encoders\")\n",
    "    print(f\"  ‚úÖ standard_scaler.pkl: scaler para {len(numeric_cols_used)} features\")\n",
    "    \n",
    "    # Guardar lista de columnas\n",
    "    feature_info = {\n",
    "        'feature_columns': feature_columns,\n",
    "        'numeric_original': numeric_cols_original,\n",
    "        'numeric_new': numeric_cols_new,\n",
    "        'categorical_original': ['Soil Type', 'Crop Type'],\n",
    "        'categorical_new': [f for f in new_features_list if f in ['Temp_Cat', 'Hum_Cat', 'N_Level', 'K_Level', 'P_Level', 'Soil_Crop_Combo']],\n",
    "        'encoded_columns': [col for col in encoded_cols if col in feature_columns],\n",
    "        'target_column': 'Fertilizer Name_encoded',\n",
    "        'target_original': 'Fertilizer Name'\n",
    "    }\n",
    "    \n",
    "    joblib.dump(feature_info, f'{processed_dir}/feature_info.pkl')\n",
    "    print(f\"  ‚úÖ feature_info.pkl: informaci√≥n de {len(feature_columns)} features\")\n",
    "    \n",
    "    # 3. DATASETS COMPLETOS CON √çNDICE ID (OPTIMIZADO)\n",
    "    print(\"\\n3Ô∏è‚É£ Guardando datasets completos con √≠ndice 'id'...\")\n",
    "    \n",
    "    # Train completo procesado (mantiene el √≠ndice 'id' autom√°ticamente con parquet)\n",
    "    train_complete = train_final.copy()\n",
    "    train_complete.to_parquet(f'{processed_dir}/train_complete_processed.parquet')\n",
    "    print(f\"  ‚úÖ train_complete_processed.parquet: {train_complete.shape} (con √≠ndice 'id')\")\n",
    "    \n",
    "    # Test completo procesado (mantiene el √≠ndice 'id' autom√°ticamente con parquet)\n",
    "    test_complete = test_final.copy()\n",
    "    test_complete.to_parquet(f'{processed_dir}/test_complete_processed.parquet')\n",
    "    print(f\"  ‚úÖ test_complete_processed.parquet: {test_complete.shape} (con √≠ndice 'id')\")\n",
    "    \n",
    "    print(\"\\nüéâ Todos los datasets guardados exitosamente\")\n",
    "    return True\n",
    "\n",
    "# Ejecutar guardado\n",
    "save_success = save_processed_datasets()\n",
    "\n",
    "if save_success:\n",
    "    print(f\"\\nüéâ ¬°PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\\n\")\n",
    "    \n",
    "    print(f\"üìÅ ARCHIVOS GUARDADOS EN: {processed_dir}\")\n",
    "    print(f\"\\nüìä RESUMEN FINAL:\")\n",
    "    print(f\"  ‚Ä¢ Datasets listos para: Random Forest, LightGBM, XGBoost\")\n",
    "    print(f\"  ‚Ä¢ Features totales: {len(feature_columns)}\")\n",
    "    print(f\"  ‚Ä¢ Train/Validation: 80/20 estratificado\")\n",
    "    print(f\"  ‚Ä¢ Random state: 513\")\n",
    "    print(f\"  ‚Ä¢ Escalado: StandardScaler aplicado\")\n",
    "    print(f\"  ‚Ä¢ Encoding: Label Encoding para categ√≥ricas\")\n",
    "    \n",
    "    print(f\"\\nüöÄ PR√ìXIMOS PASOS:\")\n",
    "    print(f\"  1. Cargar datasets desde /data/processed/\")\n",
    "    print(f\"  2. Implementar modelos TIER 1\")\n",
    "    print(f\"  3. Evaluar performance con validation set\")\n",
    "    print(f\"  4. Generar predicciones para submission\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ¬°Listos para modelado!\")\n",
    "else:\n",
    "    print(f\"‚ùå Error en el guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69451c5e",
   "metadata": {},
   "source": [
    "## ‚úÖ Verificaci√≥n Final y Pr√≥ximos Pasos\n",
    "\n",
    "### üîç Resumen del Preprocesamiento:\n",
    "\n",
    "1. **‚úÖ Feature Engineering Completado**: Todas las variables del EDA recreadas\n",
    "2. **‚úÖ Encoding Aplicado**: Label Encoding para m√°xima compatibilidad \n",
    "3. **‚úÖ Escalado Realizado**: StandardScaler para normalizaci√≥n\n",
    "4. **‚úÖ Divisi√≥n Train/Val**: 80/20 estratificado con random_state=513\n",
    "5. **‚úÖ Datasets Guardados**: Listos para modelos en `/data/processed/`\n",
    "\n",
    "### üéØ Modelos Preparados Para:\n",
    "- **Random Forest**: Baseline robusto\n",
    "- **LightGBM**: Gradient boosting eficiente  \n",
    "- **XGBoost**: Gradient boosting de alta performance\n",
    "\n",
    "### üìÅ Archivos Generados (Optimizados):\n",
    "```\n",
    "data/processed/\n",
    "‚îú‚îÄ‚îÄ X_train.parquet, X_val.parquet, y_train.parquet, y_val.parquet  # Datasets divididos\n",
    "‚îú‚îÄ‚îÄ X_test.parquet                                                    # Test para predicci√≥n\n",
    "‚îú‚îÄ‚îÄ label_encoders.pkl                                                # Encoders categ√≥ricos\n",
    "‚îú‚îÄ‚îÄ standard_scaler.pkl                                               # Scaler num√©rico\n",
    "‚îú‚îÄ‚îÄ feature_info.pkl                                                  # Metadatos de features\n",
    "‚îî‚îÄ‚îÄ train/test_complete_processed.parquet                            # Datasets completos (con √≠ndice 'id')\n",
    "```\n",
    "\n",
    "### üìÑ C√≥mo cargar los archivos:\n",
    "```python\n",
    "# Cargar datasets principales\n",
    "X_train = pd.read_parquet('../data/processed/X_train.parquet')\n",
    "y_train = pd.read_parquet('../data/processed/y_train.parquet')\n",
    "\n",
    "# Cargar datasets completos (con √≠ndice 'id')\n",
    "test_complete = pd.read_parquet('../data/processed/test_complete_processed.parquet')\n",
    "```\n",
    "\n",
    "### üöÄ ¬°Preprocesamiento completado! Listos para fase de modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6fba7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
