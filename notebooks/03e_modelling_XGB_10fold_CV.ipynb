{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311624b8",
   "metadata": {},
   "source": [
    "# üöÄ XGBoost con 10-Fold Cross-Validation - Predicci√≥n de Fertilizantes\n",
    "\n",
    "> **Objetivo**: Combinar la importaci√≥n de datos del modelado TIER 1 con validaci√≥n cruzada robusta de 10-fold para predecir **nombres de fertilizantes** optimizando MAP@3.\n",
    "> \n",
    "> **Variable Objetivo**: `Fertilizer Name` (nombres de fertilizantes codificados)\n",
    "> \n",
    "> **Estrategia**: Usar ModelTrainer para cargar datos preprocesados y aplicar 10-fold CV con XGBoost optimizado\n",
    "> \n",
    "> **M√©trica Principal**: MAP@3 (Mean Average Precision at 3) - requerida por la competencia de Kaggle\n",
    "> \n",
    "> **Mejoras**: Configuraci√≥n corregida de early stopping y ensemble de modelos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb332602",
   "metadata": {},
   "source": [
    "## üìö 1. Importar Librer√≠as y Datos\n",
    "\n",
    "### Importaci√≥n de librer√≠as necesarias y carga de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Utilidades del proyecto\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from model_utils import ModelTrainer, print_feature_selection_summary, print_training_config\n",
    "from visuals import plot_confusion_matrix, plot_feature_importance\n",
    "from metrics import mapk\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "# Configuraci√≥n\n",
    "np.random.seed(513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar trainer y cargar datos preprocesados\n",
    "trainer = ModelTrainer('XGBClassifier', 'XGB')\n",
    "data = trainer.load_data()\n",
    "\n",
    "# Extraer datasets\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_val, y_val = data['X_val'], data['y_val']\n",
    "X_test = data['X_test']\n",
    "feature_info = data['feature_info']\n",
    "label_encoders = data['label_encoders']\n",
    "fertilizer_encoder = label_encoders['Fertilizer Name']\n",
    "\n",
    "print(\"üìä Datos cargados exitosamente:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_val shape: {X_val.shape}\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ Variable objetivo: {y_train.name}\")\n",
    "print(f\"  ‚Ä¢ Clases objetivo: {len(fertilizer_encoder.classes_)}\")\n",
    "\n",
    "# Mostrar las clases de fertilizantes\n",
    "print(f\"\\nüß™ CLASES DE FERTILIZANTES:\")\n",
    "for i, class_name in enumerate(fertilizer_encoder.classes_):\n",
    "    print(f\"  {i}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee804",
   "metadata": {},
   "source": [
    "## üéØ 2. Selecci√≥n de Features\n",
    "\n",
    "### Definiendo las caracter√≠sticas que utilizaremos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECCI√ìN DE FEATURES PARA EL MODELO\n",
    "# =============================================================================\n",
    "\n",
    "features_to_use = [\n",
    "    # üå°Ô∏è VARIABLES CLIM√ÅTICAS ORIGINALES\n",
    "    'Temparature',\n",
    "    'Humidity', \n",
    "    'Moisture',\n",
    "    \n",
    "    # üå± VARIABLES DE SUELO Y CULTIVO (CODIFICADAS)\n",
    "    # NOTA: XGBoost puede usar categ√≥ricas directamente con 'enable_categorical=True'\n",
    "    # pero para mayor compatibilidad usamos las versiones codificadas\n",
    "    # 'Soil Type',     # ‚ùå Categ√≥rica sin codificar (requiere enable_categorical=True)\n",
    "    # 'Crop Type',     # ‚ùå Categ√≥rica sin codificar (requiere enable_categorical=True)\n",
    "\n",
    "    # üß™ VARIABLES QU√çMICAS (NPK)\n",
    "    'Nitrogen',\n",
    "    'Potassium', \n",
    "    'Phosphorous',\n",
    "    \n",
    "    # üìä FEATURES ENGINEERED - RATIOS NPK\n",
    "    # 'N_P_ratio',\n",
    "    # 'N_K_ratio',\n",
    "    # 'P_K_ratio',\n",
    "    # 'Total_NPK',\n",
    "    \n",
    "    # üå°Ô∏è FEATURES ENGINEERED - √çNDICES CLIM√ÅTICOS\n",
    "    # 'Temp_Hum_index',\n",
    "    # 'Moist_Balance',\n",
    "    # 'Environ_Stress',\n",
    "    \n",
    "    # # üè∑Ô∏è FEATURES ENGINEERED - CATEGOR√çAS\n",
    "    # 'Temp_Cat',\n",
    "    # 'Hum_Cat',\n",
    "    # 'N_Level',\n",
    "    # 'K_Level',\n",
    "    # 'P_Level',\n",
    "\n",
    "    # üîó FEATURES ENGINEERED - COMBINACIONES\n",
    "    # 'Soil_Crop_Combo',\n",
    "    # 'NPK_Balance',\n",
    "    # 'Dominant_NPK_Level',\n",
    "    # 'Temp_Moist_inter',\n",
    "    \n",
    "    # üî¢ FEATURES ENCODED (CATEG√ìRICAS) - ‚úÖ HABILITADAS\n",
    "    'Soil Type_encoded',      # ‚úÖ Versi√≥n codificada de Soil Type\n",
    "    'Crop Type_encoded',      # ‚úÖ Versi√≥n codificada de Crop Type\n",
    "    # 'Temp_Cat_encoded',\n",
    "    # 'Hum_Cat_encoded',\n",
    "    # 'N_Level_encoded',\n",
    "    # 'K_Level_encoded',\n",
    "    # 'P_Level_encoded',\n",
    "    # 'Soil_Crop_Combo_encoded'\n",
    "]\n",
    "\n",
    "# Validar features disponibles\n",
    "features_to_use = trainer.validate_features(features_to_use, X_train)\n",
    "print_feature_selection_summary(features_to_use, features_to_use)\n",
    "\n",
    "print(f\"\\n‚úÖ Features seleccionadas: {len(features_to_use)}\")\n",
    "print(f\"üìä Dimensi√≥n final: {X_train[features_to_use].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5d67f",
   "metadata": {},
   "source": [
    "## üîÑ 3. Configuraci√≥n de Validaci√≥n Cruzada\n",
    "\n",
    "### Configuraci√≥n de validaci√≥n cruzada estratificada con k-fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea40e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DE VALIDACI√ìN CRUZADA ESTRATIFICADA\n",
    "# =============================================================================\n",
    "\n",
    "# Combinar datos de entrenamiento y validaci√≥n para CV completa\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä DATOS COMBINADOS PARA CV:\")\n",
    "print(f\"  ‚Ä¢ X_full shape: {X_full.shape}\")\n",
    "print(f\"  ‚Ä¢ y_full shape: {y_full.shape}\")\n",
    "print(f\"  ‚Ä¢ Features a usar: {len(features_to_use)}\")\n",
    "\n",
    "# Par√°metros de CV\n",
    "N_SPLITS = 10  # 10-fold cross-validation\n",
    "RANDOM_STATE = 513\n",
    "SHUFFLE = True\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_SPLITS, \n",
    "    shuffle=SHUFFLE, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÑ CONFIGURACI√ìN DE VALIDACI√ìN CRUZADA:\")\n",
    "print(f\"  ‚Ä¢ N√∫mero de folds: {N_SPLITS}\")\n",
    "print(f\"  ‚Ä¢ Estratificada: S√≠ (mantiene proporci√≥n de clases)\")\n",
    "print(f\"  ‚Ä¢ Shuffle: {SHUFFLE}\")\n",
    "print(f\"  ‚Ä¢ Random state: {RANDOM_STATE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5299b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Configuraci√≥n de Hiperpar√°metros XGBoost\n",
    "\n",
    "### Definiendo los par√°metros optimizados del modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DE HIPERPAR√ÅMETROS XGBOOST OPTIMIZADA\n",
    "# =============================================================================\n",
    "\n",
    "# Configuraci√≥n optimizada basada en an√°lisis previos\n",
    "xgb_params = {\n",
    "    # Par√°metros principales\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(features_to_use.classes_),  # N√∫mero de clases objetivo\n",
    "    'eval_metric': 'mlogloss',\n",
    "    \n",
    "    # Estructura del √°rbol\n",
    "    'max_depth': 12,\n",
    "    'n_estimators': 4000,  # Alto n√∫mero con early stopping\n",
    "    'learning_rate': 0.03,\n",
    "    \n",
    "    # Regularizaci√≥n\n",
    "    'reg_alpha': 2.7,      # L1 regularization\n",
    "    'reg_lambda': 1.4,     # L2 regularization\n",
    "    'gamma': 0.26,         # Minimum split loss\n",
    "    'max_delta_step': 4,   # Para clases desbalanceadas\n",
    "    \n",
    "    # Muestreo\n",
    "    'subsample': 0.86,\n",
    "    'colsample_bytree': 0.467,\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'colsample_bynode': 0.8,\n",
    "    \n",
    "    # Optimizaci√≥n\n",
    "    'tree_method': 'hist',\n",
    "    'enable_categorical': True,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configuraci√≥n de early stopping (CORREGIDA)\n",
    "EARLY_STOPPING_ROUNDS = 100\n",
    "VERBOSE_EVAL = 200\n",
    "\n",
    "print(f\"‚öôÔ∏è CONFIGURACI√ìN XGBOOST: {N_SPLITS}-fold CV\")\n",
    "print(f\"  ‚Ä¢ Estimators: {xgb_params['n_estimators']} | Early stopping: {EARLY_STOPPING_ROUNDS}\")\n",
    "print(f\"  ‚Ä¢ Learning rate: {xgb_params['learning_rate']} | Max depth: {xgb_params['max_depth']}\")\n",
    "print(f\"  ‚Ä¢ Clases objetivo: {xgb_params['num_class']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d735d",
   "metadata": {},
   "source": [
    "## üöÄ 5. Entrenamiento del Modelo con Validaci√≥n Cruzada\n",
    "\n",
    "### Entrenamiento con 10-fold CV y ensemble de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTRENAMIENTO CON 10-FOLD CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üöÄ INICIANDO ENTRENAMIENTO CON {N_SPLITS}-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Inicializar variables para almacenar resultados\n",
    "fold_results = []\n",
    "oof_predictions = np.zeros((len(X_full), len(fertilizer_encoder.classes_)))\n",
    "feature_importance_folds = []\n",
    "trained_models = []\n",
    "\n",
    "# Calcular class weights globales para balance\n",
    "class_counts = Counter(y_full)\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {cls: max_count / count for cls, count in class_counts.items()}\n",
    "\n",
    "print(f\"‚öñÔ∏è CLASS WEIGHTS PARA BALANCE:\")\n",
    "for cls, weight in class_weights.items():\n",
    "    class_name = fertilizer_encoder.classes_[cls]\n",
    "    print(f\"  {cls} ({class_name:15}): {weight:.3f}\")\n",
    "\n",
    "# Tiempo de inicio\n",
    "start_time = time.time()\n",
    "\n",
    "# Entrenamiento por folds\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full[features_to_use], y_full), 1):\n",
    "    print(f\"\\n{'='*20} FOLD {fold}/{N_SPLITS} {'='*20}\")\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_train_fold = X_full[features_to_use].iloc[train_idx]\n",
    "    X_val_fold = X_full[features_to_use].iloc[val_idx]\n",
    "    y_train_fold = y_full.iloc[train_idx]\n",
    "    y_val_fold = y_full.iloc[val_idx]\n",
    "    \n",
    "    print(f\"üìä Train size: {len(X_train_fold):,} | Val size: {len(X_val_fold):,}\")\n",
    "    \n",
    "    # Calcular sample weights para este fold\n",
    "    fold_class_counts = Counter(y_train_fold)\n",
    "    fold_max_count = max(fold_class_counts.values())\n",
    "    sample_weights = y_train_fold.map(lambda cls: fold_max_count / fold_class_counts[cls])\n",
    "    \n",
    "    # Inicializar modelo con early stopping en el constructor (CORREGIDO)\n",
    "    model = XGBClassifier(\n",
    "        **xgb_params,\n",
    "        callbacks=[EarlyStopping(rounds=EARLY_STOPPING_ROUNDS, save_best=True)]\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo (early stopping corregido)\n",
    "    model.fit(\n",
    "        X_train_fold,\n",
    "        y_train_fold,\n",
    "        sample_weight=sample_weights,\n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        verbose=VERBOSE_EVAL if fold == 1 else 0  # Solo verbose en el primer fold\n",
    "    )\n",
    "    \n",
    "    # Predicciones\n",
    "    val_pred_proba = model.predict_proba(X_val_fold)\n",
    "    val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # Guardar predicciones OOF\n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_val_fold, val_pred)\n",
    "    \n",
    "    # MAP@3\n",
    "    top3_preds = np.argsort(val_pred_proba, axis=1)[:, ::-1][:, :3]\n",
    "    map3_score = mapk(y_val_fold.tolist(), top3_preds.tolist(), k=3)\n",
    "    \n",
    "    # Guardar resultados del fold\n",
    "    fold_time = time.time() - fold_start_time\n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy,\n",
    "        'map3': map3_score,\n",
    "        'best_iteration': getattr(model, 'best_iteration', model.n_estimators),\n",
    "        'training_time': fold_time\n",
    "    })\n",
    "    \n",
    "    # Guardar modelo e importancia\n",
    "    trained_models.append(model)\n",
    "    feature_importance_folds.append(model.feature_importances_)\n",
    "    \n",
    "    print(f\"‚úÖ Fold {fold} completado:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   MAP@3: {map3_score:.4f}\")\n",
    "    # print(f\"   Best iteration: {getattr(model, 'best_iteration', model.n_estimators)}\")\n",
    "    # print(f\"   Tiempo: {fold_time:.1f}s\")\n",
    "\n",
    "# Tiempo total\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è ENTRENAMIENTO COMPLETADO en {total_time:.1f}s ({total_time/60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7da959",
   "metadata": {},
   "source": [
    "## üìä 6. Evaluaci√≥n del Modelo\n",
    "\n",
    "### An√°lisis completo de rendimiento y m√©tricas de validaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACI√ìN COMPLETA DE RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä RESULTADOS DE VALIDACI√ìN CRUZADA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "# Estad√≠sticas de accuracy\n",
    "accuracy_mean = results_df['accuracy'].mean()\n",
    "accuracy_std = results_df['accuracy'].std()\n",
    "accuracy_min = results_df['accuracy'].min()\n",
    "accuracy_max = results_df['accuracy'].max()\n",
    "\n",
    "# Estad√≠sticas de MAP@3\n",
    "map3_mean = results_df['map3'].mean()\n",
    "map3_std = results_df['map3'].std()\n",
    "map3_min = results_df['map3'].min()\n",
    "map3_max = results_df['map3'].max()\n",
    "\n",
    "# # Mostrar resultados por fold\n",
    "# print(\"üìã RESULTADOS POR FOLD:\")\n",
    "# print(\"Fold  Accuracy   MAP@3    Best Iter  Time(s)\")\n",
    "# print(\"-\" * 45)\n",
    "# for _, row in results_df.iterrows():\n",
    "#     print(f\"{row['fold']:2.0f}    {row['accuracy']:.4f}   {row['map3']:.4f}   {row['best_iteration']:6.0f}    {row['training_time']:6.1f}\")\n",
    "\n",
    "# print(\"-\" * 45)\n",
    "# print(f\"Mean  {accuracy_mean:.4f}   {map3_mean:.4f}\")\n",
    "# print(f\"Std   {accuracy_std:.4f}   {map3_std:.4f}\")\n",
    "# \n",
    "# Resumen estad√≠stico\n",
    "print(f\"\\nüéØ M√âTRICAS FINALES:\")\n",
    "print(f\"  üìà Accuracy promedio: {accuracy_mean:.4f} ¬± {accuracy_std:.4f}\")\n",
    "print(f\"  üìà MAP@3 promedio:    {map3_mean:.4f} ¬± {map3_std:.4f}\")\n",
    "print(f\"  üìä Rango Accuracy:    [{accuracy_min:.4f}, {accuracy_max:.4f}]\")\n",
    "print(f\"  üìä Rango MAP@3:       [{map3_min:.4f}, {map3_max:.4f}]\")\n",
    "\n",
    "# Evaluaci√≥n de estabilidad\n",
    "accuracy_cv = accuracy_std / accuracy_mean\n",
    "map3_cv = map3_std / map3_mean\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE ESTABILIDAD:\")\n",
    "print(f\"  üìä Coeficiente de variaci√≥n (Accuracy): {accuracy_cv:.3f}\")\n",
    "print(f\"  üìä Coeficiente de variaci√≥n (MAP@3):    {map3_cv:.3f}\")\n",
    "print(f\"  {'‚úÖ Modelo estable' if accuracy_cv < 0.05 else '‚ö†Ô∏è Modelo variable'} (Accuracy CV < 0.05)\")\n",
    "print(f\"  {'‚úÖ Modelo estable' if map3_cv < 0.05 else '‚ö†Ô∏è Modelo variable'} (MAP@3 CV < 0.05)\")\n",
    "\n",
    "# Tiempo promedio por fold\n",
    "avg_fold_time = results_df['training_time'].mean()\n",
    "print(f\"\\n‚è±Ô∏è TIEMPOS DE ENTRENAMIENTO:\")\n",
    "print(f\"  üìä Tiempo promedio por fold: {avg_fold_time:.1f}s\")\n",
    "print(f\"  üìä Tiempo total: {total_time:.1f}s ({total_time/60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACI√ìN OUT-OF-FOLD (OOF)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç EVALUACI√ìN OUT-OF-FOLD (OOF)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Predicciones OOF finales\n",
    "oof_pred = np.argmax(oof_predictions, axis=1)\n",
    "oof_accuracy = accuracy_score(y_full, oof_pred)\n",
    "\n",
    "# MAP@3 con predicciones OOF\n",
    "oof_top3 = np.argsort(oof_predictions, axis=1)[:, ::-1][:, :3]\n",
    "oof_map3 = mapk(y_full.tolist(), oof_top3.tolist(), k=3)\n",
    "\n",
    "print(f\"üìä M√âTRICAS OOF (predicciones combinadas):\")\n",
    "print(f\"  üéØ OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "print(f\"  üéØ OOF MAP@3:    {oof_map3:.4f}\")\n",
    "\n",
    "# Comparaci√≥n con CV\n",
    "print(f\"\\nüìä COMPARACI√ìN CV vs OOF:\")\n",
    "print(f\"  Accuracy: CV={accuracy_mean:.4f} | OOF={oof_accuracy:.4f} | Diff={abs(accuracy_mean-oof_accuracy):.4f}\")\n",
    "print(f\"  MAP@3:    CV={map3_mean:.4f} | OOF={oof_map3:.4f} | Diff={abs(map3_mean-oof_map3):.4f}\")\n",
    "\n",
    "# M√©tricas por clase\n",
    "print(f\"\\nüìä M√âTRICAS POR CLASE (OOF):\")\n",
    "class_report = classification_report(y_full, oof_pred, \n",
    "                                   target_names=fertilizer_encoder.classes_,\n",
    "                                   output_dict=True)\n",
    "\n",
    "print(\"Clase            Precision  Recall  F1-Score  Support\")\n",
    "print(\"-\" * 55)\n",
    "for class_name in fertilizer_encoder.classes_:\n",
    "    metrics = class_report[class_name]\n",
    "    print(f\"{class_name:15} {metrics['precision']:8.3f} {metrics['recall']:7.3f} {metrics['f1-score']:8.3f} {metrics['support']:8.0f}\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "macro_avg = class_report['macro avg']\n",
    "print(f\"{'Macro avg':15} {macro_avg['precision']:8.3f} {macro_avg['recall']:7.3f} {macro_avg['f1-score']:8.3f} {macro_avg['support']:8.0f}\")\n",
    "weighted_avg = class_report['weighted avg']\n",
    "print(f\"{'Weighted avg':15} {weighted_avg['precision']:8.3f} {weighted_avg['recall']:7.3f} {weighted_avg['f1-score']:8.3f} {weighted_avg['support']:8.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53577d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calcular importancia promedio\n",
    "feature_importance_mean = np.mean(feature_importance_folds, axis=0)\n",
    "feature_importance_std = np.std(feature_importance_folds, axis=0)\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features_to_use,\n",
    "    'importance_mean': feature_importance_mean,\n",
    "    'importance_std': feature_importance_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "# # Mostrar top 10 caracter√≠sticas\n",
    "# print(f\"üìä TOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES:\")\n",
    "# print(\"Rank  Feature               Importance    Std Dev\")\n",
    "# print(\"-\" * 50)\n",
    "# for i, (_, row) in enumerate(importance_df.head(10).iterrows()):\n",
    "#     print(f\"{i+1:2d}.   {row['feature']:20} {row['importance_mean']:8.4f}   ¬±{row['importance_std']:6.4f}\")\n",
    "\n",
    "# # Generar gr√°fico de importancia\n",
    "# try:\n",
    "#     feature_importance_plot_df = plot_feature_importance(\n",
    "#         feature_importances=feature_importance_mean,\n",
    "#         feature_names=features_to_use,\n",
    "#         title=\"Importancia de Features - XGBoost 10-Fold CV\"\n",
    "#     )\n",
    "#     print(f\"\\nüìà Gr√°fico de importancia generado\")\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n‚ö†Ô∏è Error al generar gr√°fico: {e}\")\n",
    "\n",
    "# An√°lisis de tipos de caracter√≠sticas\n",
    "# print(f\"\\nüìä AN√ÅLISIS POR TIPO DE CARACTER√çSTICA:\")\n",
    "numeric_features = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "engineered_features = [f for f in features_to_use if any(keyword in f for keyword in ['ratio', 'index', 'Balance', 'Total', 'inter'])]\n",
    "encoded_features = [f for f in features_to_use if '_encoded' in f]\n",
    "\n",
    "numeric_importance = importance_df[importance_df['feature'].isin(numeric_features)]['importance_mean'].sum()\n",
    "engineered_importance = importance_df[importance_df['feature'].isin(engineered_features)]['importance_mean'].sum()\n",
    "encoded_importance = importance_df[importance_df['feature'].isin(encoded_features)]['importance_mean'].sum()\n",
    "total_importance = numeric_importance + engineered_importance + encoded_importance\n",
    "\n",
    "# print(f\"  üî¢ Caracter√≠sticas num√©ricas:    {numeric_importance:.3f} ({numeric_importance/total_importance*100:.1f}%)\")\n",
    "# print(f\"  ‚öôÔ∏è Features engineered:         {engineered_importance:.3f} ({engineered_importance/total_importance*100:.1f}%)\")\n",
    "# print(f\"  üè∑Ô∏è Caracter√≠sticas categ√≥ricas: {encoded_importance:.3f} ({encoded_importance/total_importance*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524143e",
   "metadata": {},
   "source": [
    "## üéØ 7. Generaci√≥n de Predicciones para Test\n",
    "\n",
    "### Predicciones finales usando ensemble de 10 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERACI√ìN DE PREDICCIONES PARA TEST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ GENERANDO PREDICCIONES PARA CONJUNTO DE TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensemble de predicciones de todos los modelos\n",
    "print(f\"üìä Ensemble de {len(trained_models)} modelos entrenados...\")\n",
    "\n",
    "test_predictions_all = []\n",
    "for i, model in enumerate(trained_models):\n",
    "    pred_proba = model.predict_proba(X_test[features_to_use])\n",
    "    test_predictions_all.append(pred_proba)\n",
    "    if i < 3:  # Mostrar progreso para los primeros 3\n",
    "        print(f\"  ‚úÖ Modelo {i+1}: Predicciones generadas\")\n",
    "\n",
    "if len(trained_models) > 3:\n",
    "    print(f\"  ‚úÖ ... y {len(trained_models)-3} modelos m√°s\")\n",
    "\n",
    "# Promedio de las predicciones (ensemble)\n",
    "test_predictions_ensemble = np.mean(test_predictions_all, axis=0)\n",
    "print(f\"üìä Shape de predicciones ensemble: {test_predictions_ensemble.shape}\")\n",
    "\n",
    "# Obtener √≠ndices de las top 3 clases para cada muestra\n",
    "test_top3_indices = np.argsort(test_predictions_ensemble, axis=1)[:, ::-1][:, :3]\n",
    "print(f\"üìä Shape de top-3 √≠ndices: {test_top3_indices.shape}\")\n",
    "\n",
    "# Convertir √≠ndices a nombres de fertilizantes\n",
    "test_top3_names = []\n",
    "for i in range(len(test_top3_indices)):\n",
    "    top3_for_sample = []\n",
    "    for j in range(3):\n",
    "        class_idx = test_top3_indices[i, j]\n",
    "        class_name = fertilizer_encoder.classes_[class_idx]\n",
    "        top3_for_sample.append(class_name)\n",
    "    test_top3_names.append(top3_for_sample)\n",
    "\n",
    "print(f\"‚úÖ Conversi√≥n a nombres completada\")\n",
    "\n",
    "# # Verificar algunas predicciones\n",
    "# print(f\"\\nüîç MUESTRA DE PREDICCIONES (primeras 5):\")\n",
    "# for i in range(5):\n",
    "#     probs = test_predictions_ensemble[i]\n",
    "#     top3_names = test_top3_names[i]\n",
    "#     top3_probs = [probs[test_top3_indices[i, j]] for j in range(3)]\n",
    "    \n",
    "#     print(f\"  Muestra {i+1}:\")\n",
    "#     for j in range(3):\n",
    "#         print(f\"    {j+1}. {top3_names[j]:15} (prob: {top3_probs[j]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09ef9c",
   "metadata": {},
   "source": [
    "## üéâ 8. Resumen Final y Conclusiones\n",
    "\n",
    "### Resultados del modelo combinado con 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d41a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Creaci√≥n del Archivo de Submission =====\n",
    "# print(f\"\\nüìù CREANDO ARCHIVO DE SUBMISSION\")\n",
    "# print(\"=\" * 40)\n",
    "\n",
    "# # Formatear predicciones como string separado por espacios\n",
    "# submission_predictions = []\n",
    "# for top3_names in test_top3_names:\n",
    "#     prediction_string = ' '.join(top3_names)\n",
    "#     submission_predictions.append(prediction_string)\n",
    "\n",
    "# print(f\"üìä Predicciones formateadas: {len(submission_predictions)}\")\n",
    "\n",
    "# # Crear DataFrame de submission\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': X_test.index,\n",
    "#     'Fertilizer Name': submission_predictions\n",
    "# })\n",
    "\n",
    "# print(f\"üìä Shape del submission: {submission.shape}\")\n",
    "# print(f\"üìä Columnas: {list(submission.columns)}\")\n",
    "\n",
    "# # Verificar el formato\n",
    "# print(f\"\\nüîç VERIFICACI√ìN DEL FORMATO:\")\n",
    "# print(f\"  ‚úÖ Columnas requeridas: ['id', 'Fertilizer Name']\")\n",
    "# print(f\"  ‚úÖ N√∫mero de filas: {len(submission)} (debe ser {len(X_test)})\")\n",
    "# print(f\"  ‚úÖ IDs √∫nicos: {submission['id'].nunique()} (debe ser {len(X_test)})\")\n",
    "# print(f\"  ‚úÖ Sin valores nulos: {submission.isnull().sum().sum() == 0}\")\n",
    "\n",
    "# # Mostrar muestra del submission\n",
    "# print(f\"\\nüìã MUESTRA DEL SUBMISSION (primeras 10 filas):\")\n",
    "# display(submission.head(10))\n",
    "\n",
    "# # Verificar formato de predicciones\n",
    "# print(f\"\\nüîç VERIFICACI√ìN DE FORMATO DE PREDICCIONES:\")\n",
    "# sample_predictions = submission['Fertilizer Name'].head(5).tolist()\n",
    "# for i, pred in enumerate(sample_predictions):\n",
    "#     fertilizers = pred.split(' ')\n",
    "#     print(f\"  Fila {i+1}: {len(fertilizers)} fertilizantes -> {pred}\")\n",
    "#     if len(fertilizers) != 3:\n",
    "#         print(f\"    ‚ö†Ô∏è ERROR: Se esperan 3 fertilizantes, se encontraron {len(fertilizers)}\")\n",
    "\n",
    "# # Guardar archivo\n",
    "# submission_filename = f'xgboost_fertilizer_submission_MAP3_{map3_mean:.4f}.csv'\n",
    "# submission.to_csv(submission_filename, index=False)\n",
    "# print(f\"\\nüíæ ARCHIVO GUARDADO: {submission_filename}\")\n",
    "\n",
    "# # Estad√≠sticas finales\n",
    "# print(f\"\\nüìä ESTAD√çSTICAS FINALES:\")\n",
    "# print(f\"  üéØ Modelo: XGBoost Ensemble ({len(trained_models)} folds)\")\n",
    "# print(f\"  üìà MAP@3 promedio (CV): {map3_mean:.4f} ¬± {map3_std:.4f}\")\n",
    "# print(f\"  üìà Accuracy promedio (CV): {accuracy_mean:.4f} ¬± {accuracy_std:.4f}\")\n",
    "# print(f\"  üìä Predicciones generadas: {len(submission):,}\")\n",
    "# print(f\"  üíæ Archivo: {submission_filename}\")\n",
    "# print(f\"  ‚è±Ô∏è Tiempo total: {total_time/60:.1f} minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # RESUMEN FINAL\n",
    "# # =============================================================================\n",
    "\n",
    "# print(f\"\\nüéâ RESUMEN FINAL - XGBOOST 10-FOLD CV\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# print(f\"üìä ESTAD√çSTICAS FINALES:\")\n",
    "# print(f\"  üéØ Modelo: XGBoost Ensemble ({len(trained_models)} folds)\")\n",
    "# print(f\"  üìà MAP@3 promedio (CV): {map3_mean:.4f} ¬± {map3_std:.4f}\")\n",
    "# print(f\"  üìà Accuracy promedio (CV): {accuracy_mean:.4f} ¬± {accuracy_std:.4f}\")\n",
    "# print(f\"  üìà OOF MAP@3: {oof_map3:.4f}\")\n",
    "# print(f\"  üìà OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "# print(f\"  üìä Features utilizadas: {len(features_to_use)}\")\n",
    "# print(f\"  üìä Predicciones generadas: {len(submission):,}\")\n",
    "# print(f\"  üíæ Archivo: {submission_filename}\")\n",
    "# print(f\"  ‚è±Ô∏è Tiempo total: {total_time/60:.1f} minutos\")\n",
    "\n",
    "# print(f\"\\nüîß CONFIGURACI√ìN MODELO:\")\n",
    "# print(f\"  ‚Ä¢ Algoritmo: XGBoost con early stopping corregido\")\n",
    "# print(f\"  ‚Ä¢ Validaci√≥n: {N_SPLITS}-Fold Stratified Cross Validation\")\n",
    "# print(f\"  ‚Ä¢ Balance: Sample weights autom√°tico\")\n",
    "# print(f\"  ‚Ä¢ Ensemble: Promedio de {len(trained_models)} modelos\")\n",
    "# print(f\"  ‚Ä¢ Early stopping: {EARLY_STOPPING_ROUNDS} rounds\")\n",
    "\n",
    "# print(f\"\\nüèÜ MEJORAS IMPLEMENTADAS:\")\n",
    "# print(f\"  ‚úÖ Combinaci√≥n de datos train + validation para CV completa\")\n",
    "# print(f\"  ‚úÖ Configuraci√≥n corregida de early stopping en callbacks\")\n",
    "# print(f\"  ‚úÖ Hiperpar√°metros optimizados del archivo 03c\")\n",
    "# print(f\"  ‚úÖ Features engineered y selecci√≥n autom√°tica\")\n",
    "# print(f\"  ‚úÖ Ensemble robusto de 10 modelos\")\n",
    "# print(f\"  ‚úÖ Sample weights para balance de clases\")\n",
    "\n",
    "# if map3_mean > 0.32:\n",
    "#     print(f\"\\nüéØ ¬°OBJETIVO ALCANZADO! MAP@3 = {map3_mean:.4f} > 0.32\")\n",
    "# else:\n",
    "#     print(f\"\\nüìà Resultado: MAP@3 = {map3_mean:.4f} (objetivo: > 0.32)\")\n",
    "\n",
    "# print(f\"\\n‚úÖ Notebook completado exitosamente\")\n",
    "# print(f\"üìÅ Submission guardado en: {submission_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaeaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN PARA GUARDADO DE ARCHIVOS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar nombre del modelo basado en MAP@3\n",
    "model_name = f\"XGB_10CV_MAP@3-{oof_map3:.5f}\".replace('.', '')\n",
    "model_dir = f\"../models/XGB/{N_SPLITS}CV/{model_name}\"\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ DIRECTORIO DEL MODELO:\")\n",
    "print(f\"  {model_dir}\")\n",
    "\n",
    "# Configuraci√≥n de nombres de archivos\n",
    "base_filename = model_name\n",
    "files_to_create = {\n",
    "    'hparams': f\"{base_filename}_hparams.json\",\n",
    "    'metrics': f\"{base_filename}_metrics.json\",\n",
    "    'metrics_pkl': f\"{base_filename}_metrics.pkl\",\n",
    "    'model_pkl': f\"{base_filename}_model.pkl\",\n",
    "    'feature_import': f\"{base_filename}_feature_importance.csv\",\n",
    "    'submission': f\"{base_filename}_submission.csv\",\n",
    "    'submission_info': f\"{base_filename}_submission_info.json\"\n",
    "}\n",
    "\n",
    "print(f\"\\nüìù ARCHIVOS A CREAR:\")\n",
    "for file_type, filename in files_to_create.items():\n",
    "    print(f\"  {file_type:15}: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR HIPERPAR√ÅMETROS\n",
    "# =============================================================================\n",
    "\n",
    "hparams_data = {\n",
    "    \"model_type\": \"XGBClassifier\",\n",
    "    \"model_abbreviation\": \"XGB\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \"ensemble_method\": \"Average of fold predictions\",\n",
    "    \"hyperparameters\": xgb_params,\n",
    "    \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "    \"features_selected\": features_to_use,\n",
    "    \"num_features\": len(features_to_use),\n",
    "    \"class_weights_used\": True,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"cv_splits\": N_SPLITS,\n",
    "    \"total_models\": len(trained_models)\n",
    "}\n",
    "\n",
    "# Guardar hiperpar√°metros\n",
    "hparams_file = os.path.join(model_dir, files_to_create['hparams'])\n",
    "with open(hparams_file, 'w') as f:\n",
    "    json.dump(hparams_data, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697983d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR M√âTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "# M√©tricas principales para JSON\n",
    "metrics_data = {\n",
    "    \"model_type\": \"XGBClassifier\",\n",
    "    \"model_abbreviation\": \"XGB\",\n",
    "    \"tier\": \"10_FOLD_CV\",\n",
    "    \"target_variable\": \"Fertilizer Name\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \n",
    "    # M√©tricas principales\n",
    "    \"map3_score_cv_mean\": float(map3_mean),\n",
    "    \"map3_score_cv_std\": float(map3_std),\n",
    "    \"map3_score_oof\": float(oof_map3),\n",
    "    \"accuracy_cv_mean\": float(accuracy_mean),\n",
    "    \"accuracy_cv_std\": float(accuracy_std),\n",
    "    \"accuracy_oof\": float(oof_accuracy),\n",
    "    \n",
    "    # Informaci√≥n del modelo\n",
    "    \"num_classes\": len(fertilizer_encoder.classes_),\n",
    "    \"features_used\": len(features_to_use),\n",
    "    \"features_list\": features_to_use,\n",
    "    \"cv_folds\": N_SPLITS,\n",
    "    \"total_models_trained\": len(trained_models),\n",
    "    \n",
    "    # M√©tricas por fold\n",
    "    \"fold_results\": fold_results,\n",
    "    \n",
    "    # Estad√≠sticas de estabilidad\n",
    "    \"accuracy_cv_coefficient\": float(accuracy_cv),\n",
    "    \"map3_cv_coefficient\": float(map3_cv),\n",
    "    \n",
    "    # Tiempos\n",
    "    \"training_time_total\": float(total_time),\n",
    "    \"training_time_per_fold_avg\": float(avg_fold_time),\n",
    "    \n",
    "    # Metadatos\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"kaggle_competition\": \"playground-series-s5e6\"\n",
    "}\n",
    "\n",
    "# Guardar m√©tricas JSON\n",
    "metrics_file = os.path.join(model_dir, files_to_create['metrics'])\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "\n",
    "# M√©tricas completas para PKL (incluye objetos complejos)\n",
    "metrics_pkl_data = {\n",
    "    **metrics_data,\n",
    "    \"oof_predictions\": oof_predictions,\n",
    "    \"trained_models\": trained_models,\n",
    "    \"feature_importance_folds\": feature_importance_folds,\n",
    "    \"class_report\": class_report,\n",
    "    \"confusion_matrix\": confusion_matrix(y_full, oof_pred),\n",
    "    \"fertilizer_encoder\": fertilizer_encoder\n",
    "}\n",
    "\n",
    "# Guardar m√©tricas PKL\n",
    "metrics_pkl_file = os.path.join(model_dir, files_to_create['metrics_pkl'])\n",
    "joblib.dump(metrics_pkl_data, metrics_pkl_file, compress=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR IMPORTANCIA DE CARACTER√çSTICAS\n",
    "# =============================================================================\n",
    "\n",
    "# Guardar DataFrame de importancia\n",
    "feature_importance_file = os.path.join(model_dir, files_to_create['feature_import'])\n",
    "importance_df.to_csv(feature_importance_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR MODELOS ENTRENADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Guardar el ensemble de modelos entrenados\n",
    "model_data = {\n",
    "    \"ensemble_models\": trained_models,\n",
    "    \"model_type\": \"XGBClassifier\",\n",
    "    \"cv_folds\": N_SPLITS,\n",
    "    \"features_used\": features_to_use,\n",
    "    \"hyperparameters\": xgb_params,\n",
    "    \"label_encoder\": fertilizer_encoder,\n",
    "    \"training_info\": {\n",
    "        \"map3_cv_mean\": float(map3_mean),\n",
    "        \"map3_oof\": float(oof_map3),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar modelos\n",
    "model_file = os.path.join(model_dir, files_to_create['model_pkl'])\n",
    "joblib.dump(model_data, model_file, compress=3)\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR SUBMISSION Y INFORMACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "# Crear submission directamente desde predicciones del ensemble\n",
    "print(f\"üìù Creando submission desde ensemble de {len(trained_models)} modelos...\")\n",
    "\n",
    "# Formatear predicciones como string separado por espacios\n",
    "submission_predictions = []\n",
    "for top3_names in test_top3_names:\n",
    "    prediction_string = ' '.join(top3_names)\n",
    "    submission_predictions.append(prediction_string)\n",
    "\n",
    "# Crear DataFrame de submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test.index,  # Usar √≠ndice de X_test como ID\n",
    "    'Fertilizer Name': submission_predictions\n",
    "})\n",
    "\n",
    "# Guardar archivo de submission\n",
    "submission_file = os.path.join(model_dir, files_to_create['submission'])\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "# Informaci√≥n del submission\n",
    "submission_info = {\n",
    "    \"model_type\": \"XGBClassifier\",\n",
    "    \"model_abbreviation\": \"XGB\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \"map3_score_cv_mean\": float(map3_mean),\n",
    "    \"map3_score_oof\": float(oof_map3),\n",
    "    \"submission_file\": files_to_create['submission'],\n",
    "    \"num_predictions\": len(submission),\n",
    "    \"format\": \"MAP@3 - Top 3 fertilizer names separated by spaces\",\n",
    "    \"target_variable\": \"Fertilizer Name\",\n",
    "    \"ensemble_models\": len(trained_models),\n",
    "    \"features_used\": len(features_to_use),\n",
    "    \"total_training_time_minutes\": float(total_time / 60),\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"kaggle_competition\": \"playground-series-s5e6\"\n",
    "}\n",
    "\n",
    "# Guardar informaci√≥n del submission\n",
    "submission_info_file = os.path.join(model_dir, files_to_create['submission_info'])\n",
    "with open(submission_info_file, 'w') as f:\n",
    "    json.dump(submission_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR SUBMISSION Y INFORMACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "# Guardar archivo de submission\n",
    "submission_file = os.path.join(model_dir, files_to_create['submission'])\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "# Informaci√≥n del submission\n",
    "submission_info = {\n",
    "    \"model_type\": \"XGBClassifier\",\n",
    "    \"model_abbreviation\": \"XGB\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \"map3_score_cv_mean\": float(map3_mean),\n",
    "    \"map3_score_oof\": float(oof_map3),\n",
    "    \"submission_file\": files_to_create['submission'],\n",
    "    \"num_predictions\": len(submission),\n",
    "    \"format\": \"MAP@3 - Top 3 fertilizer names separated by spaces\",\n",
    "    \"target_variable\": \"Fertilizer Name\",\n",
    "    \"ensemble_models\": len(trained_models),\n",
    "    \"features_used\": len(features_to_use),\n",
    "    \"total_training_time_minutes\": float(total_time / 60),\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"kaggle_competition\": \"playground-series-s5e6\"\n",
    "}\n",
    "\n",
    "# Guardar informaci√≥n del submission\n",
    "submission_info_file = os.path.join(model_dir, files_to_create['submission_info'])\n",
    "with open(submission_info_file, 'w') as f:\n",
    "    json.dump(submission_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ba37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RESUMEN FINAL DE ARCHIVOS GUARDADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüíæ RESUMEN FINAL - ARCHIVOS GUARDADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìÅ DIRECTORIO: {model_dir}\")\n",
    "print(f\"\\nüìÑ ARCHIVOS CREADOS:\")\n",
    "\n",
    "# Verificar y mostrar todos los archivos creados\n",
    "for file_type, filename in files_to_create.items():\n",
    "    file_path = os.path.join(model_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        if file_size > 1024*1024:  # > 1MB\n",
    "            size_str = f\"{file_size/(1024*1024):.1f} MB\"\n",
    "        elif file_size > 1024:  # > 1KB\n",
    "            size_str = f\"{file_size/1024:.1f} KB\"\n",
    "        else:\n",
    "            size_str = f\"{file_size} bytes\"\n",
    "        \n",
    "        print(f\"  ‚úÖ {filename:35} ({size_str})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {filename:35} (NO CREADO)\")\n",
    "\n",
    "print(f\"\\nüéØ M√âTRICAS PRINCIPALES:\")\n",
    "print(f\"  üìä MAP@3 (CV Mean): {map3_mean:.5f} ¬± {map3_std:.5f}\")\n",
    "print(f\"  üìä MAP@3 (OOF):     {oof_map3:.5f}\")\n",
    "print(f\"  üìä Accuracy (OOF):  {oof_accuracy:.5f}\")\n",
    "print(f\"  ü§ñ Modelos:         {len(trained_models)} (ensemble)\")\n",
    "print(f\"  üìä Features:        {len(features_to_use)}\")\n",
    "print(f\"  ‚è±Ô∏è Tiempo total:    {total_time/60:.1f} minutos\")\n",
    "\n",
    "print(f\"\\nüéâ TODOS LOS ARCHIVOS GUARDADOS EXITOSAMENTE\")\n",
    "print(f\"üìÇ Ubicaci√≥n: {os.path.abspath(model_dir)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
