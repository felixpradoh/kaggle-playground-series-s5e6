{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc19289",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos - Kaggle Playground Series S5E6\n",
    "## Fertilizer Prediction: Data Preprocessing Pipeline\n",
    "\n",
    "**Autor:** FÃ©lix  \n",
    "**Fecha:** 2025-01-21  \n",
    "**Objetivo:** Preparar datos para modelado basÃ¡ndose en insights del EDA\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ **Pipeline de Preprocesamiento**\n",
    "\n",
    "**ğŸ¯ Basado en conclusiones del EDA 01_eda_template.ipynb:**\n",
    "\n",
    "1. **Feature Engineering**: Implementar las 20+ features identificadas como valiosas\n",
    "2. **Encoding**: Variables categÃ³ricas con high cardinality (Soil_Crop_Combo)\n",
    "3. **Scaling**: Preparar variables numÃ©ricas para Random Forest baseline\n",
    "4. **Splitting**: DivisiÃ³n estratificada para 22 clases de fertilizantes\n",
    "5. **Export**: Datasets listos para modelado\n",
    "\n",
    "**ğŸ“Š Dataset Original:**\n",
    "- 750,000 muestras\n",
    "- 22 tipos de fertilizantes\n",
    "- 9 variables predictoras + features engineered\n",
    "- Sin valores faltantes\n",
    "\n",
    "**ğŸ¯ Target Final:** Datos optimizados para Random Forest baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb53c72",
   "metadata": {},
   "source": [
    "## ğŸ“š 1. ImportaciÃ³n de LibrerÃ­as\n",
    "\n",
    "### LibrerÃ­as para Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36ec496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LibrerÃ­as importadas correctamente\n",
      "ğŸ“Š Pandas: 2.2.3\n",
      "ğŸ”¢ NumPy: 2.2.6\n",
      "ğŸ¤– Scikit-learn: sklearn disponible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Para visualizaciÃ³n (opcional en preprocessing)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(f\"ğŸ“Š Pandas: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy: {np.__version__}\")\n",
    "print(f\"ğŸ¤– Scikit-learn: sklearn disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17092a4b",
   "metadata": {},
   "source": [
    "## ğŸ“Š 2. Carga de Datos\n",
    "\n",
    "### Carga de Datasets Originales\n",
    "\n",
    "Cargamos los datos desde los archivos CSV y verificamos su estructura bÃ¡sica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83ff625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARGA DE DATOS ===\n",
      "\n",
      "ğŸ“ Archivos cargados:\n",
      "  â€¢ Train: (750000, 10) (filas, columnas)\n",
      "  â€¢ Test: (250000, 9)\n",
      "  â€¢ Sample Submission: (250000, 2)\n",
      "\n",
      "ğŸ” Columnas en Train:\n",
      "  ['id', 'Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'Fertilizer Name']\n",
      "\n",
      "ğŸ” Columnas en Test:\n",
      "  ['id', 'Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
      "\n",
      "ğŸ“Š Info Train Dataset:\n",
      "  â€¢ Tipos de datos Ãºnicos: {dtype('int64'): 7, dtype('O'): 3}\n",
      "  â€¢ Valores nulos: 0\n",
      "  â€¢ Fertilizantes Ãºnicos: 7\n",
      "\n",
      "âœ… Datos cargados correctamente - Listos para preprocesamiento\n",
      "\n",
      "ğŸ“ Archivos cargados:\n",
      "  â€¢ Train: (750000, 10) (filas, columnas)\n",
      "  â€¢ Test: (250000, 9)\n",
      "  â€¢ Sample Submission: (250000, 2)\n",
      "\n",
      "ğŸ” Columnas en Train:\n",
      "  ['id', 'Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous', 'Fertilizer Name']\n",
      "\n",
      "ğŸ” Columnas en Test:\n",
      "  ['id', 'Temparature', 'Humidity', 'Moisture', 'Soil Type', 'Crop Type', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
      "\n",
      "ğŸ“Š Info Train Dataset:\n",
      "  â€¢ Tipos de datos Ãºnicos: {dtype('int64'): 7, dtype('O'): 3}\n",
      "  â€¢ Valores nulos: 0\n",
      "  â€¢ Fertilizantes Ãºnicos: 7\n",
      "\n",
      "âœ… Datos cargados correctamente - Listos para preprocesamiento\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets\n",
    "print(\"=== CARGA DE DATOS ===\")\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(f\"\\nğŸ“ Archivos cargados:\")\n",
    "print(f\"  â€¢ Train: {train_df.shape} (filas, columnas)\")\n",
    "print(f\"  â€¢ Test: {test_df.shape}\")\n",
    "print(f\"  â€¢ Sample Submission: {sample_submission.shape}\")\n",
    "\n",
    "# Verificar estructura\n",
    "print(f\"\\nğŸ” Columnas en Train:\")\n",
    "print(f\"  {list(train_df.columns)}\")\n",
    "\n",
    "print(f\"\\nğŸ” Columnas en Test:\")\n",
    "print(f\"  {list(test_df.columns)}\")\n",
    "\n",
    "# Info bÃ¡sica\n",
    "print(f\"\\nğŸ“Š Info Train Dataset:\")\n",
    "print(f\"  â€¢ Tipos de datos Ãºnicos: {train_df.dtypes.value_counts().to_dict()}\")\n",
    "print(f\"  â€¢ Valores nulos: {train_df.isnull().sum().sum()}\")\n",
    "print(f\"  â€¢ Fertilizantes Ãºnicos: {train_df['Fertilizer Name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nâœ… Datos cargados correctamente - Listos para preprocesamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede6fec6",
   "metadata": {},
   "source": [
    "## ğŸ•³ï¸ 3. AnÃ¡lisis de Valores Faltantes\n",
    "\n",
    "### VerificaciÃ³n de Calidad de Datos\n",
    "\n",
    "**SegÃºn el EDA:** El dataset no presenta valores faltantes, pero verificamos para confirmar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55774f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÃLISIS DE VALORES FALTANTES ===\n",
      "\n",
      "ğŸ“Š DATASET DE ENTRENAMIENTO:\n",
      "  âœ… No hay valores faltantes\n",
      "  ğŸ“‹ Resumen de calidad:\n",
      "    â€¢ Filas totales: 750,000\n",
      "    â€¢ Columnas totales: 10\n",
      "  âœ… No hay valores faltantes\n",
      "  ğŸ“‹ Resumen de calidad:\n",
      "    â€¢ Filas totales: 750,000\n",
      "    â€¢ Columnas totales: 10\n",
      "    â€¢ Valores duplicados: 0\n",
      "    â€¢ Valores duplicados: 0\n",
      "    â€¢ Memoria utilizada: 157.8 MB\n",
      "\n",
      "ğŸ“Š DATASET DE PRUEBA:\n",
      "  âœ… No hay valores faltantes\n",
      "  ğŸ“‹ Resumen de calidad:\n",
      "    â€¢ Filas totales: 250,000\n",
      "    â€¢ Columnas totales: 9\n",
      "    â€¢ Memoria utilizada: 157.8 MB\n",
      "\n",
      "ğŸ“Š DATASET DE PRUEBA:\n",
      "  âœ… No hay valores faltantes\n",
      "  ğŸ“‹ Resumen de calidad:\n",
      "    â€¢ Filas totales: 250,000\n",
      "    â€¢ Columnas totales: 9\n",
      "    â€¢ Valores duplicados: 0\n",
      "    â€¢ Memoria utilizada: 39.5 MB\n",
      "\n",
      "ğŸ”„ CONSISTENCIA ENTRE DATASETS:\n",
      "  â€¢ Columnas comunes: 9 de 9\n",
      "    ['Nitrogen', 'Phosphorous', 'Temparature', 'Soil Type', 'Crop Type', 'Moisture', 'Potassium', 'id', 'Humidity']\n",
      "\n",
      "ğŸ“Š Rangos de variables numÃ©ricas (Train vs Test):\n",
      "  â€¢ Temparature    : Train [25.0, 38.0] | Test [25.0, 38.0]\n",
      "  â€¢ Humidity       : Train [50.0, 72.0] | Test [50.0, 72.0]\n",
      "  â€¢ Moisture       : Train [25.0, 65.0] | Test [25.0, 65.0]\n",
      "  â€¢ Nitrogen       : Train [4.0, 42.0] | Test [4.0, 42.0]\n",
      "  â€¢ Potassium      : Train [0.0, 19.0] | Test [0.0, 19.0]\n",
      "  â€¢ Phosphorous    : Train [0.0, 42.0] | Test [0.0, 42.0]\n",
      "\n",
      "ğŸ“Š CategorÃ­as Ãºnicas (Train vs Test):\n",
      "    â€¢ Valores duplicados: 0\n",
      "    â€¢ Memoria utilizada: 39.5 MB\n",
      "\n",
      "ğŸ”„ CONSISTENCIA ENTRE DATASETS:\n",
      "  â€¢ Columnas comunes: 9 de 9\n",
      "    ['Nitrogen', 'Phosphorous', 'Temparature', 'Soil Type', 'Crop Type', 'Moisture', 'Potassium', 'id', 'Humidity']\n",
      "\n",
      "ğŸ“Š Rangos de variables numÃ©ricas (Train vs Test):\n",
      "  â€¢ Temparature    : Train [25.0, 38.0] | Test [25.0, 38.0]\n",
      "  â€¢ Humidity       : Train [50.0, 72.0] | Test [50.0, 72.0]\n",
      "  â€¢ Moisture       : Train [25.0, 65.0] | Test [25.0, 65.0]\n",
      "  â€¢ Nitrogen       : Train [4.0, 42.0] | Test [4.0, 42.0]\n",
      "  â€¢ Potassium      : Train [0.0, 19.0] | Test [0.0, 19.0]\n",
      "  â€¢ Phosphorous    : Train [0.0, 42.0] | Test [0.0, 42.0]\n",
      "\n",
      "ğŸ“Š CategorÃ­as Ãºnicas (Train vs Test):\n",
      "  â€¢ Soil Type:\n",
      "    Train: 5 categorÃ­as\n",
      "    Test: 5 categorÃ­as\n",
      "    âœ… Todas las categorÃ­as de test estÃ¡n en train\n",
      "  â€¢ Crop Type:\n",
      "    Train: 11 categorÃ­as\n",
      "    Test: 11 categorÃ­as\n",
      "    âœ… Todas las categorÃ­as de test estÃ¡n en train\n",
      "\n",
      "ğŸ¯ CONCLUSIÃ“N ANÃLISIS DE CALIDAD:\n",
      "  âœ… Datasets limpios - sin valores faltantes\n",
      "  âœ… Consistencia entre train y test verificada\n",
      "  âœ… Listos para feature engineering\n",
      "  â€¢ Soil Type:\n",
      "    Train: 5 categorÃ­as\n",
      "    Test: 5 categorÃ­as\n",
      "    âœ… Todas las categorÃ­as de test estÃ¡n en train\n",
      "  â€¢ Crop Type:\n",
      "    Train: 11 categorÃ­as\n",
      "    Test: 11 categorÃ­as\n",
      "    âœ… Todas las categorÃ­as de test estÃ¡n en train\n",
      "\n",
      "ğŸ¯ CONCLUSIÃ“N ANÃLISIS DE CALIDAD:\n",
      "  âœ… Datasets limpios - sin valores faltantes\n",
      "  âœ… Consistencia entre train y test verificada\n",
      "  âœ… Listos para feature engineering\n"
     ]
    }
   ],
   "source": [
    "# AnÃ¡lisis de valores faltantes\n",
    "print(\"=== ANÃLISIS DE VALORES FALTANTES ===\")\n",
    "\n",
    "# FunciÃ³n para analizar valores faltantes\n",
    "def analyze_missing_values(df, dataset_name):\n",
    "    print(f\"\\nğŸ“Š {dataset_name}:\")\n",
    "    \n",
    "    # Contar nulos\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Crear resumen\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Columna': df.columns,\n",
    "        'Valores_Nulos': null_counts.values,\n",
    "        'Porcentaje': null_percentages.values\n",
    "    }).sort_values('Valores_Nulos', ascending=False)\n",
    "    \n",
    "    # Mostrar solo columnas con valores faltantes\n",
    "    has_nulls = missing_summary[missing_summary['Valores_Nulos'] > 0]\n",
    "    \n",
    "    if len(has_nulls) > 0:\n",
    "        print(f\"  âš ï¸ Columnas con valores faltantes:\")\n",
    "        for _, row in has_nulls.iterrows():\n",
    "            print(f\"    â€¢ {row['Columna']}: {row['Valores_Nulos']} ({row['Porcentaje']:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  âœ… No hay valores faltantes\")\n",
    "    \n",
    "    # Verificar otros problemas de calidad\n",
    "    print(f\"  ğŸ“‹ Resumen de calidad:\")\n",
    "    print(f\"    â€¢ Filas totales: {len(df):,}\")\n",
    "    print(f\"    â€¢ Columnas totales: {len(df.columns)}\")\n",
    "    print(f\"    â€¢ Valores duplicados: {df.duplicated().sum():,}\")\n",
    "    print(f\"    â€¢ Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    return missing_summary\n",
    "\n",
    "# Analizar ambos datasets\n",
    "train_missing = analyze_missing_values(train_df, \"DATASET DE ENTRENAMIENTO\")\n",
    "test_missing = analyze_missing_values(test_df, \"DATASET DE PRUEBA\")\n",
    "\n",
    "# Verificar consistencia entre train y test\n",
    "print(f\"\\nğŸ”„ CONSISTENCIA ENTRE DATASETS:\")\n",
    "\n",
    "# Columnas comunes (excluyendo target)\n",
    "common_cols = set(test_df.columns) & set(train_df.columns)\n",
    "print(f\"  â€¢ Columnas comunes: {len(common_cols)} de {len(test_df.columns)}\")\n",
    "print(f\"    {list(common_cols)}\")\n",
    "\n",
    "# Verificar rangos de variables numÃ©ricas\n",
    "numeric_cols = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "print(f\"\\nğŸ“Š Rangos de variables numÃ©ricas (Train vs Test):\")\n",
    "for col in numeric_cols:\n",
    "    if col in train_df.columns and col in test_df.columns:\n",
    "        train_range = f\"[{train_df[col].min():.1f}, {train_df[col].max():.1f}]\"\n",
    "        test_range = f\"[{test_df[col].min():.1f}, {test_df[col].max():.1f}]\"\n",
    "        print(f\"  â€¢ {col:15}: Train {train_range} | Test {test_range}\")\n",
    "\n",
    "# Verificar categorÃ­as Ãºnicas\n",
    "categorical_cols = ['Soil Type', 'Crop Type']\n",
    "print(f\"\\nğŸ“Š CategorÃ­as Ãºnicas (Train vs Test):\")\n",
    "for col in categorical_cols:\n",
    "    if col in train_df.columns and col in test_df.columns:\n",
    "        train_cats = set(train_df[col].unique())\n",
    "        test_cats = set(test_df[col].unique())\n",
    "        \n",
    "        print(f\"  â€¢ {col}:\")\n",
    "        print(f\"    Train: {len(train_cats)} categorÃ­as\")\n",
    "        print(f\"    Test: {len(test_cats)} categorÃ­as\")\n",
    "        \n",
    "        # CategorÃ­as solo en test (problemas potenciales)\n",
    "        only_in_test = test_cats - train_cats\n",
    "        if only_in_test:\n",
    "            print(f\"    âš ï¸ Solo en Test: {only_in_test}\")\n",
    "        else:\n",
    "            print(f\"    âœ… Todas las categorÃ­as de test estÃ¡n en train\")\n",
    "\n",
    "print(f\"\\nğŸ¯ CONCLUSIÃ“N ANÃLISIS DE CALIDAD:\")\n",
    "print(f\"  âœ… Datasets limpios - sin valores faltantes\")\n",
    "print(f\"  âœ… Consistencia entre train y test verificada\")\n",
    "print(f\"  âœ… Listos para feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c22a5",
   "metadata": {},
   "source": [
    "## âš™ï¸ 4. Feature Engineering\n",
    "\n",
    "### CreaciÃ³n de Features Basadas en Insights del EDA\n",
    "\n",
    "**ğŸ¯ Implementamos las features que demostraron alto valor predictivo en el EDA:**\n",
    "\n",
    "1. **Ratios de Nutrientes**: N_P_ratio, N_K_ratio, P_K_ratio\n",
    "2. **Ãndices Ambientales**: Temp_Humidity_index, Environmental_Stress\n",
    "3. **CategorizaciÃ³n de Nutrientes**: N_Level, P_Level, K_Level\n",
    "4. **Interacciones Contextuales**: Soil_Crop_Combo\n",
    "5. **Features Agregadas**: Total_NPK, Balance de humedad\n",
    "\n",
    "**ğŸ“Š Resultado esperado:** 20+ features totales para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af13c33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE ENGINEERING ESTRATÃ‰GICO ===\n",
      "ğŸ”§ Aplicando feature engineering...\n",
      "\n",
      "ğŸ”§ Creando features para TRAIN...\n",
      "  1ï¸âƒ£ Ratios de nutrientes...\n",
      "  2ï¸âƒ£ Ãndices ambientales...\n",
      "  3ï¸âƒ£ CategorizaciÃ³n de nutrientes...\n",
      "  3ï¸âƒ£ CategorizaciÃ³n de nutrientes...\n",
      "  4ï¸âƒ£ Interacciones contextuales...\n",
      "  4ï¸âƒ£ Interacciones contextuales...\n",
      "  5ï¸âƒ£ Features de balance y ratios avanzados...\n",
      "  5ï¸âƒ£ Features de balance y ratios avanzados...\n",
      "  ğŸ¯ Target numÃ©rico creado para uso interno\n",
      "  âœ… Features creadas: 17\n",
      "  ğŸ“Š Total columnas: 10 â†’ 27\n",
      "\n",
      "ğŸ”§ Creando features para TEST...\n",
      "  1ï¸âƒ£ Ratios de nutrientes...\n",
      "  2ï¸âƒ£ Ãndices ambientales...\n",
      "  3ï¸âƒ£ CategorizaciÃ³n de nutrientes...\n",
      "  ğŸ¯ Target numÃ©rico creado para uso interno\n",
      "  âœ… Features creadas: 17\n",
      "  ğŸ“Š Total columnas: 10 â†’ 27\n",
      "\n",
      "ğŸ”§ Creando features para TEST...\n",
      "  1ï¸âƒ£ Ratios de nutrientes...\n",
      "  2ï¸âƒ£ Ãndices ambientales...\n",
      "  3ï¸âƒ£ CategorizaciÃ³n de nutrientes...\n",
      "  4ï¸âƒ£ Interacciones contextuales...\n",
      "  4ï¸âƒ£ Interacciones contextuales...\n",
      "  5ï¸âƒ£ Features de balance y ratios avanzados...\n",
      "  âœ… Features creadas: 16\n",
      "  ğŸ“Š Total columnas: 9 â†’ 25\n",
      "\n",
      "ğŸ“Š RESUMEN DE FEATURE ENGINEERING:\n",
      "\n",
      "ğŸ”¢ Nuevas features numÃ©ricas (10):\n",
      "  â€¢ N_P_ratio                : [0.10, 420.00]\n",
      "  â€¢ N_K_ratio                : [0.21, 420.00]\n",
      "  â€¢ P_K_ratio                : [0.00, 420.00]\n",
      "  â€¢ Total_NPK                : [4.00, 103.00]\n",
      "  â€¢ Temp_Humidity_index      : [12.50, 27.36]\n",
      "  â€¢ Moisture_Balance         : [-47.00, 15.00]\n",
      "  â€¢ Environmental_Stress     : [0.00, 17.67]\n",
      "  â€¢ NPK_Balance              : [0.00, 84.00]\n",
      "  â€¢ Dominant_Nutrient_Level  : [4.00, 42.00]\n",
      "  â€¢ Temp_Moisture_interaction: [6.25, 24.70]\n",
      "\n",
      "ğŸ“Š Nuevas features categÃ³ricas (6):\n",
      "  â€¢ Temp_Category       : 3 categorÃ­as Ãºnicas\n",
      "  5ï¸âƒ£ Features de balance y ratios avanzados...\n",
      "  âœ… Features creadas: 16\n",
      "  ğŸ“Š Total columnas: 9 â†’ 25\n",
      "\n",
      "ğŸ“Š RESUMEN DE FEATURE ENGINEERING:\n",
      "\n",
      "ğŸ”¢ Nuevas features numÃ©ricas (10):\n",
      "  â€¢ N_P_ratio                : [0.10, 420.00]\n",
      "  â€¢ N_K_ratio                : [0.21, 420.00]\n",
      "  â€¢ P_K_ratio                : [0.00, 420.00]\n",
      "  â€¢ Total_NPK                : [4.00, 103.00]\n",
      "  â€¢ Temp_Humidity_index      : [12.50, 27.36]\n",
      "  â€¢ Moisture_Balance         : [-47.00, 15.00]\n",
      "  â€¢ Environmental_Stress     : [0.00, 17.67]\n",
      "  â€¢ NPK_Balance              : [0.00, 84.00]\n",
      "  â€¢ Dominant_Nutrient_Level  : [4.00, 42.00]\n",
      "  â€¢ Temp_Moisture_interaction: [6.25, 24.70]\n",
      "\n",
      "ğŸ“Š Nuevas features categÃ³ricas (6):\n",
      "  â€¢ Temp_Category       : 3 categorÃ­as Ãºnicas\n",
      "  â€¢ N_Level             : 3 categorÃ­as Ãºnicas\n",
      "  â€¢ P_Level             : 3 categorÃ­as Ãºnicas\n",
      "  â€¢ K_Level             : 2 categorÃ­as Ãºnicas\n",
      "  â€¢ Soil_Crop_Combo     : 55 categorÃ­as Ãºnicas\n",
      "  â€¢ N_Level             : 3 categorÃ­as Ãºnicas\n",
      "  â€¢ P_Level             : 3 categorÃ­as Ãºnicas\n",
      "  â€¢ K_Level             : 2 categorÃ­as Ãºnicas\n",
      "  â€¢ Soil_Crop_Combo     : 55 categorÃ­as Ãºnicas\n",
      "  â€¢ NPK_Level_Combo     : 18 categorÃ­as Ãºnicas\n",
      "\n",
      "ğŸ¯ FEATURE ENGINEERING COMPLETADO:\n",
      "  â€¢ Train: (750000, 10) â†’ (750000, 27)\n",
      "  â€¢ Test: (250000, 9) â†’ (250000, 25)\n",
      "  â€¢ Features totales disponibles: 27\n",
      "  âœ… Listos para codificaciÃ³n de variables categÃ³ricas\n",
      "  â€¢ NPK_Level_Combo     : 18 categorÃ­as Ãºnicas\n",
      "\n",
      "ğŸ¯ FEATURE ENGINEERING COMPLETADO:\n",
      "  â€¢ Train: (750000, 10) â†’ (750000, 27)\n",
      "  â€¢ Test: (250000, 9) â†’ (250000, 25)\n",
      "  â€¢ Features totales disponibles: 27\n",
      "  âœ… Listos para codificaciÃ³n de variables categÃ³ricas\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering completo basado en insights del EDA\n",
    "print(\"=== FEATURE ENGINEERING ESTRATÃ‰GICO ===\")\n",
    "\n",
    "# FunciÃ³n para crear todas las features\n",
    "def create_features(df, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Crear todas las features basadas en insights del EDA\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ”§ Creando features para {dataset_name}...\")\n",
    "    \n",
    "    # Hacer copia para no modificar original\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 1. RATIOS DE NUTRIENTES (Alto valor predictivo segÃºn MI)\n",
    "    print(\"  1ï¸âƒ£ Ratios de nutrientes...\")\n",
    "    df_features['N_P_ratio'] = df_features['Nitrogen'] / (df_features['Phosphorous'] + 0.1)  # +0.1 para evitar divisiÃ³n por 0\n",
    "    df_features['N_K_ratio'] = df_features['Nitrogen'] / (df_features['Potassium'] + 0.1)\n",
    "    df_features['P_K_ratio'] = df_features['Phosphorous'] / (df_features['Potassium'] + 0.1)\n",
    "    df_features['Total_NPK'] = df_features['Nitrogen'] + df_features['Phosphorous'] + df_features['Potassium']\n",
    "    \n",
    "    # 2. ÃNDICES AMBIENTALES\n",
    "    print(\"  2ï¸âƒ£ Ãndices ambientales...\")\n",
    "    df_features['Temp_Humidity_index'] = df_features['Temparature'] * df_features['Humidity'] / 100\n",
    "    df_features['Moisture_Balance'] = df_features['Moisture'] - df_features['Humidity']\n",
    "    df_features['Environmental_Stress'] = (abs(df_features['Temparature'] - 25) + \n",
    "                                         abs(df_features['Humidity'] - 65) + \n",
    "                                         abs(df_features['Moisture'] - 50)) / 3\n",
    "    \n",
    "    # 3. CATEGORIZACIÃ“N INTELIGENTE DE NUTRIENTES\n",
    "    print(\"  3ï¸âƒ£ CategorizaciÃ³n de nutrientes...\")\n",
    "    \n",
    "    # Temperatura (basado en anÃ¡lisis del EDA)\n",
    "    df_features['Temp_Category'] = pd.cut(df_features['Temparature'], \n",
    "                                         bins=[-np.inf, 15, 25, 35, np.inf], \n",
    "                                         labels=['FrÃ­o', 'Templado', 'CÃ¡lido', 'Muy_CÃ¡lido'])\n",
    "    \n",
    "    # Niveles de nutrientes (basados en cuartiles del EDA)\n",
    "    df_features['N_Level'] = pd.cut(df_features['Nitrogen'], \n",
    "                                   bins=[-np.inf, 15, 30, np.inf], \n",
    "                                   labels=['Bajo', 'Medio', 'Alto'])\n",
    "    \n",
    "    df_features['P_Level'] = pd.cut(df_features['Phosphorous'], \n",
    "                                   bins=[-np.inf, 20, 40, np.inf], \n",
    "                                   labels=['Bajo', 'Medio', 'Alto'])\n",
    "    \n",
    "    df_features['K_Level'] = pd.cut(df_features['Potassium'], \n",
    "                                   bins=[-np.inf, 10, 20, np.inf], \n",
    "                                   labels=['Bajo', 'Medio', 'Alto'])\n",
    "    \n",
    "    # 4. INTERACCIONES CONTEXTUALES (Alto MI segÃºn EDA)\n",
    "    print(\"  4ï¸âƒ£ Interacciones contextuales...\")\n",
    "    df_features['Soil_Crop_Combo'] = df_features['Soil Type'] + '_' + df_features['Crop Type']\n",
    "    \n",
    "    # CombinaciÃ³n de niveles NPK\n",
    "    df_features['NPK_Level_Combo'] = (df_features['N_Level'].astype(str) + '_' + \n",
    "                                     df_features['P_Level'].astype(str) + '_' + \n",
    "                                     df_features['K_Level'].astype(str))\n",
    "    \n",
    "    # 5. FEATURES ADICIONALES DE BALANCE\n",
    "    print(\"  5ï¸âƒ£ Features de balance y ratios avanzados...\")\n",
    "    \n",
    "    # Balance de macronutrientes\n",
    "    df_features['NPK_Balance'] = abs(df_features['Nitrogen'] - df_features['Phosphorous']) + \\\n",
    "                                abs(df_features['Nitrogen'] - df_features['Potassium']) + \\\n",
    "                                abs(df_features['Phosphorous'] - df_features['Potassium'])\n",
    "    \n",
    "    # Ãndice de nutriente dominante\n",
    "    max_nutrient = df_features[['Nitrogen', 'Phosphorous', 'Potassium']].max(axis=1)\n",
    "    df_features['Dominant_Nutrient_Level'] = max_nutrient\n",
    "    \n",
    "    # Condiciones ambientales combinadas\n",
    "    df_features['Temp_Moisture_interaction'] = df_features['Temparature'] * df_features['Moisture'] / 100\n",
    "    \n",
    "    # CREAR TARGET ENCODED PARA USO INTERNO (solo para train)\n",
    "    if 'Fertilizer Name' in df_features.columns:\n",
    "        # Crear target numÃ©rico para uso interno\n",
    "        target_encoder = LabelEncoder()\n",
    "        df_features['target'] = target_encoder.fit_transform(df_features['Fertilizer Name'])\n",
    "        print(\"  ğŸ¯ Target numÃ©rico creado para uso interno\")\n",
    "    \n",
    "    # Resumen de features creadas\n",
    "    original_cols = len(df.columns)\n",
    "    new_cols = len(df_features.columns)\n",
    "    features_added = new_cols - original_cols\n",
    "    \n",
    "    print(f\"  âœ… Features creadas: {features_added}\")\n",
    "    print(f\"  ğŸ“Š Total columnas: {original_cols} â†’ {new_cols}\")\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Aplicar feature engineering a ambos datasets\n",
    "print(\"ğŸ”§ Aplicando feature engineering...\")\n",
    "\n",
    "train_processed = create_features(train_df, \"TRAIN\")\n",
    "test_processed = create_features(test_df, \"TEST\")\n",
    "\n",
    "# Verificar que las features se crearon correctamente\n",
    "print(f\"\\nğŸ“Š RESUMEN DE FEATURE ENGINEERING:\")\n",
    "\n",
    "# Nuevas features numÃ©ricas\n",
    "new_numeric_features = ['N_P_ratio', 'N_K_ratio', 'P_K_ratio', 'Total_NPK',\n",
    "                       'Temp_Humidity_index', 'Moisture_Balance', 'Environmental_Stress',\n",
    "                       'NPK_Balance', 'Dominant_Nutrient_Level', 'Temp_Moisture_interaction']\n",
    "\n",
    "print(f\"\\nğŸ”¢ Nuevas features numÃ©ricas ({len(new_numeric_features)}):\")\n",
    "for feature in new_numeric_features:\n",
    "    train_range = f\"[{train_processed[feature].min():.2f}, {train_processed[feature].max():.2f}]\"\n",
    "    print(f\"  â€¢ {feature:25}: {train_range}\")\n",
    "\n",
    "# Nuevas features categÃ³ricas\n",
    "new_categorical_features = ['Temp_Category', 'N_Level', 'P_Level', 'K_Level', \n",
    "                           'Soil_Crop_Combo', 'NPK_Level_Combo']\n",
    "\n",
    "print(f\"\\nğŸ“Š Nuevas features categÃ³ricas ({len(new_categorical_features)}):\")\n",
    "for feature in new_categorical_features:\n",
    "    unique_count = train_processed[feature].nunique()\n",
    "    print(f\"  â€¢ {feature:20}: {unique_count} categorÃ­as Ãºnicas\")\n",
    "\n",
    "print(f\"\\nğŸ¯ FEATURE ENGINEERING COMPLETADO:\")\n",
    "print(f\"  â€¢ Train: {train_df.shape} â†’ {train_processed.shape}\")\n",
    "print(f\"  â€¢ Test: {test_df.shape} â†’ {test_processed.shape}\")\n",
    "print(f\"  â€¢ Features totales disponibles: {len(train_processed.columns)}\")\n",
    "print(f\"  âœ… Listos para codificaciÃ³n de variables categÃ³ricas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275ac90",
   "metadata": {},
   "source": [
    "## ğŸ”¢ 5. PreparaciÃ³n de Datos por Tipo de Modelo\n",
    "\n",
    "### Estrategia Multi-Modelo: Nativas vs Codificadas\n",
    "\n",
    "**ğŸ¯ Creamos DOS versiones optimizadas:**\n",
    "\n",
    "1. **ğŸ“Š VersiÃ³n NATIVE** (Random Forest, LightGBM, CatBoost):\n",
    "   - Variables categÃ³ricas como strings/objects\n",
    "   - Mejor manejo de alta cardinalidad\n",
    "   - Splits mÃ¡s inteligentes\n",
    "\n",
    "2. **ğŸ”¢ VersiÃ³n ENCODED** (XGBoost):\n",
    "   - LabelEncoder aplicado a categÃ³ricas\n",
    "   - Solo datos numÃ©ricos\n",
    "   - Requerido por XGBoost\n",
    "\n",
    "**ğŸ’¡ Variables categÃ³ricas identificadas:**\n",
    "- Originales: Soil Type, Crop Type\n",
    "- Nuevas: Temp_Category, N_Level, P_Level, K_Level, Soil_Crop_Combo, NPK_Level_Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307170b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARACIÃ“N MULTI-MODELO ===\n",
      "ğŸ“Š Variables categÃ³ricas identificadas: 8\n",
      "  â€¢ Soil Type: 5 categorÃ­as\n",
      "  â€¢ Soil Type: 5 categorÃ­as\n",
      "  â€¢ Crop Type: 11 categorÃ­as\n",
      "  â€¢ Temp_Category: 3 categorÃ­as\n",
      "  â€¢ N_Level: 3 categorÃ­as\n",
      "  â€¢ P_Level: 3 categorÃ­as\n",
      "  â€¢ K_Level: 2 categorÃ­as\n",
      "  â€¢ Crop Type: 11 categorÃ­as\n",
      "  â€¢ Temp_Category: 3 categorÃ­as\n",
      "  â€¢ N_Level: 3 categorÃ­as\n",
      "  â€¢ P_Level: 3 categorÃ­as\n",
      "  â€¢ K_Level: 2 categorÃ­as\n",
      "  â€¢ Soil_Crop_Combo: 55 categorÃ­as\n",
      "  â€¢ NPK_Level_Combo: 18 categorÃ­as\n",
      "\n",
      "1ï¸âƒ£ CREANDO VERSIÃ“N NATIVE (categÃ³ricas como strings):\n",
      "  â€¢ Soil_Crop_Combo: 55 categorÃ­as\n",
      "  â€¢ NPK_Level_Combo: 18 categorÃ­as\n",
      "\n",
      "1ï¸âƒ£ CREANDO VERSIÃ“N NATIVE (categÃ³ricas como strings):\n",
      "  âœ… Variables categÃ³ricas mantenidas como strings/objects\n",
      "  âœ… Target mantenido como 'Fertilizer Name': 7 clases\n",
      "  ğŸ¯ Optimizado para: Random Forest, LightGBM, CatBoost\n",
      "\n",
      "2ï¸âƒ£ CREANDO VERSIÃ“N ENCODED (todo numÃ©rico):\n",
      "  âœ… Variables categÃ³ricas mantenidas como strings/objects\n",
      "  âœ… Target mantenido como 'Fertilizer Name': 7 clases\n",
      "  ğŸ¯ Optimizado para: Random Forest, LightGBM, CatBoost\n",
      "\n",
      "2ï¸âƒ£ CREANDO VERSIÃ“N ENCODED (todo numÃ©rico):\n",
      "  ğŸ”§ Aplicando LabelEncoder a todas las categÃ³ricas...\n",
      "  ğŸ”§ Aplicando LabelEncoder a todas las categÃ³ricas...\n",
      "    ğŸ“Š Soil Type: 5 categorÃ­as â†’ [0, 4]\n",
      "    ğŸ“Š Soil Type: 5 categorÃ­as â†’ [0, 4]\n",
      "    ğŸ“Š Crop Type: 11 categorÃ­as â†’ [0, 10]\n",
      "    ğŸ“Š Crop Type: 11 categorÃ­as â†’ [0, 10]\n",
      "    ğŸ“Š Temp_Category: 3 categorÃ­as â†’ [0, 2]\n",
      "    ğŸ“Š N_Level: 3 categorÃ­as â†’ [0, 2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_encoded, test_encoded, encoders\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Aplicar codificaciÃ³n completa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m train_encoded, test_encoded, label_encoders = \u001b[43mencode_categorical_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexisting_categorical\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  âœ… Todas las variables categÃ³ricas codificadas\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  âœ… Dataset completamente numÃ©rico\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mencode_categorical_variables\u001b[39m\u001b[34m(train_df, test_df, categorical_cols, target_col)\u001b[39m\n\u001b[32m     54\u001b[39m le.fit(all_categories)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Transform train y test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m train_encoded[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_encoded\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m test_df.columns:\n\u001b[32m     59\u001b[39m     test_encoded[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_encoded\u001b[39m\u001b[33m'\u001b[39m] = le.transform(test_df[col].astype(\u001b[38;5;28mstr\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Felix\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134\u001b[39m, in \u001b[36mLabelEncoder.transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) == \u001b[32m0\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([])\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Felix\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:235\u001b[39m, in \u001b[36m_encode\u001b[39m\u001b[34m(values, uniques, check_unknown)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp.isdtype(values.dtype, \u001b[33m\"\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Felix\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[39m, in \u001b[36m_map_to_integer\u001b[39m\u001b[34m(values, uniques)\u001b[39m\n\u001b[32m    172\u001b[39m xp, _ = get_namespace(values, uniques)\n\u001b[32m    173\u001b[39m table = _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device=device(values))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# PreparaciÃ³n de datos para diferentes tipos de modelos\n",
    "print(\"=== PREPARACIÃ“N MULTI-MODELO ===\")\n",
    "\n",
    "# Identificar todas las variables categÃ³ricas\n",
    "categorical_columns = ['Soil Type', 'Crop Type', 'Temp_Category', 'N_Level', \n",
    "                      'P_Level', 'K_Level', 'Soil_Crop_Combo', 'NPK_Level_Combo']\n",
    "\n",
    "# Verificar cuÃ¡les existen en los datos\n",
    "existing_categorical = [col for col in categorical_columns if col in train_processed.columns]\n",
    "print(f\"ğŸ“Š Variables categÃ³ricas identificadas: {len(existing_categorical)}\")\n",
    "for col in existing_categorical:\n",
    "    print(f\"  â€¢ {col}: {train_processed[col].nunique()} categorÃ­as\")\n",
    "\n",
    "# ========================================\n",
    "# VERSIÃ“N 1: DATOS NATIVOS (RF, LightGBM, CatBoost)\n",
    "# ========================================\n",
    "print(f\"\\n1ï¸âƒ£ CREANDO VERSIÃ“N NATIVE (categÃ³ricas como strings):\")\n",
    "\n",
    "# Preparar versiÃ³n nativa (mantener Fertilizer Name como estÃ¡)\n",
    "train_native = train_processed.copy()\n",
    "test_native = test_processed.copy()\n",
    "\n",
    "print(f\"  âœ… Variables categÃ³ricas mantenidas como strings/objects\")\n",
    "print(f\"  âœ… Target mantenido como 'Fertilizer Name': {train_native['Fertilizer Name'].nunique()} clases\")\n",
    "print(f\"  ğŸ¯ Optimizado para: Random Forest, LightGBM, CatBoost\")\n",
    "\n",
    "# ========================================\n",
    "# VERSIÃ“N 2: DATOS CODIFICADOS (XGBoost)\n",
    "# ========================================\n",
    "print(f\"\\n2ï¸âƒ£ CREANDO VERSIÃ“N ENCODED (todo numÃ©rico):\")\n",
    "\n",
    "# FunciÃ³n para codificar variables categÃ³ricas\n",
    "def encode_categorical_variables(train_df, test_df, categorical_cols, target_col=None):\n",
    "    \"\"\"\n",
    "    Codifica TODAS las variables categÃ³ricas para XGBoost\n",
    "    \"\"\"\n",
    "    train_encoded = train_df.copy()\n",
    "    test_encoded = test_df.copy()\n",
    "    encoders = {}\n",
    "    \n",
    "    print(f\"  ğŸ”§ Aplicando LabelEncoder a todas las categÃ³ricas...\")\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in train_df.columns:\n",
    "            # Crear LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Fit en todas las categorÃ­as (train + test) para consistencia\n",
    "            all_categories = pd.concat([\n",
    "                train_df[col].astype(str), \n",
    "                test_df[col].astype(str) if col in test_df.columns else pd.Series([])\n",
    "            ]).unique()\n",
    "            \n",
    "            le.fit(all_categories)\n",
    "            \n",
    "            # Transform train y test\n",
    "            train_encoded[f'{col}_encoded'] = le.transform(train_df[col].astype(str))\n",
    "            if col in test_df.columns:\n",
    "                test_encoded[f'{col}_encoded'] = le.transform(test_df[col].astype(str))\n",
    "            \n",
    "            # Guardar encoder\n",
    "            encoders[col] = le\n",
    "            \n",
    "            print(f\"    ğŸ“Š {col}: {len(all_categories)} categorÃ­as â†’ [0, {len(all_categories)-1}]\")\n",
    "    \n",
    "    # Ya tenemos target codificado en la columna 'target'\n",
    "    if target_col and target_col in train_df.columns and 'target' in train_df.columns:\n",
    "        print(f\"    ğŸ¯ Target ya disponible como numÃ©rico en columna 'target'\")\n",
    "    \n",
    "    return train_encoded, test_encoded, encoders\n",
    "\n",
    "# Aplicar codificaciÃ³n completa\n",
    "train_encoded, test_encoded, label_encoders = encode_categorical_variables(\n",
    "    train_processed, test_processed, \n",
    "    existing_categorical\n",
    ")\n",
    "\n",
    "print(f\"  âœ… Todas las variables categÃ³ricas codificadas\")\n",
    "print(f\"  âœ… Dataset completamente numÃ©rico\")\n",
    "print(f\"  ğŸ¯ Optimizado para: XGBoost\")\n",
    "\n",
    "# ========================================\n",
    "# RESUMEN DE VERSIONES CREADAS\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“Š RESUMEN DE VERSIONES CREADAS:\")\n",
    "print(f\"\\nğŸŒ³ VERSIÃ“N NATIVE:\")\n",
    "print(f\"  â€¢ train_native: {train_native.shape}\")\n",
    "print(f\"  â€¢ test_native: {test_native.shape}\")\n",
    "print(f\"  â€¢ Variables categÃ³ricas: {len(existing_categorical)} como strings\")\n",
    "print(f\"  â€¢ Target: 'Fertilizer Name' ({train_native['Fertilizer Name'].nunique()} clases)\")\n",
    "print(f\"  â€¢ Ideal para: Random Forest, LightGBM, CatBoost\")\n",
    "\n",
    "print(f\"\\nğŸ”¢ VERSIÃ“N ENCODED:\")\n",
    "print(f\"  â€¢ train_encoded: {train_encoded.shape}\")\n",
    "print(f\"  â€¢ test_encoded: {test_encoded.shape}\")\n",
    "print(f\"  â€¢ Variables categÃ³ricas: {len(existing_categorical)} codificadas\")\n",
    "print(f\"  â€¢ Target: 'target' ({train_encoded['target'].nunique()} clases)\")\n",
    "print(f\"  â€¢ Ideal para: XGBoost\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ RECOMENDACIONES:\")\n",
    "print(f\"  ğŸ¥‡ Random Forest BASELINE: Usar train_native (mejor rendimiento)\")\n",
    "print(f\"  ğŸš€ XGBoost: Usar train_encoded (requerimiento obligatorio)\")\n",
    "print(f\"  âš¡ LightGBM: Usar train_native + categorical_feature parameter\")\n",
    "print(f\"  ğŸ¯ CatBoost: Usar train_native + cat_features parameter\")\n",
    "\n",
    "# Verificar mapeos importantes\n",
    "print(f\"\\nğŸ” MAPEOS DE ENCODERS (ejemplos):\")\n",
    "\n",
    "# Mostrar mapeo de Soil Type\n",
    "if 'Soil Type' in label_encoders:\n",
    "    soil_mapping = dict(zip(label_encoders['Soil Type'].classes_, \n",
    "                           label_encoders['Soil Type'].transform(label_encoders['Soil Type'].classes_)))\n",
    "    print(f\"  ğŸŒ± Soil Type:\")\n",
    "    for soil, code in list(soil_mapping.items())[:3]:\n",
    "        print(f\"    {code}: {soil}\")\n",
    "    if len(soil_mapping) > 3:\n",
    "        print(f\"    ... y {len(soil_mapping)-3} mÃ¡s\")\n",
    "\n",
    "# Mostrar mapeo de Crop Type (primeras 5)\n",
    "if 'Crop Type' in label_encoders:\n",
    "    crop_mapping = dict(zip(label_encoders['Crop Type'].classes_, \n",
    "                           label_encoders['Crop Type'].transform(label_encoders['Crop Type'].classes_)))\n",
    "    print(f\"  ğŸŒ¾ Crop Type (primeros 5):\")\n",
    "    for i, (crop, code) in enumerate(crop_mapping.items()):\n",
    "        if i < 5:\n",
    "            print(f\"    {code}: {crop}\")\n",
    "    if len(crop_mapping) > 5:\n",
    "        print(f\"    ... y {len(crop_mapping)-5} mÃ¡s\")\n",
    "\n",
    "# EstadÃ­sticas finales\n",
    "print(f\"\\nğŸ“ˆ ESTADÃSTICAS POST-CODIFICACIÃ“N:\")\n",
    "print(f\"  â€¢ Train shape: {train_encoded.shape}\")\n",
    "print(f\"  â€¢ Test shape: {test_encoded.shape}\")\n",
    "print(f\"  â€¢ Columnas numÃ©ricas totales: {len(train_encoded.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"  â€¢ Columnas categÃ³ricas originales mantenidas: {len(train_encoded.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "\n",
    "print(f\"\\nâœ… CODIFICACIÃ“N COMPLETADA\")\n",
    "print(f\"  ğŸ¯ Datasets listos para escalado de variables numÃ©ricas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ed2a1",
   "metadata": {},
   "source": [
    "## ğŸ”„ 6. DivisiÃ³n de Datos para Modelado\n",
    "\n",
    "### Splitting Estratificado para Ambas Versiones\n",
    "\n",
    "**ğŸ¯ Estrategia de DivisiÃ³n:**\n",
    "\n",
    "- **Split ratio**: 80/20 (entrenamiento/validaciÃ³n)\n",
    "- **EstratificaciÃ³n**: Por 22 fertilizantes\n",
    "- **Dos versiones**: Native (RF/LightGBM/CatBoost) y Encoded (XGBoost)\n",
    "- **Sin escalado**: Tree-based models no requieren normalizaciÃ³n\n",
    "\n",
    "**ğŸ“Š Datasets de salida:**\n",
    "- train_native / val_native: Para Random Forest, LightGBM, CatBoost\n",
    "- train_encoded / val_encoded: Para XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ccfed",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 7. Guardado de Datasets Preprocesados\n",
    "\n",
    "### ExportaciÃ³n de Datos Procesados\n",
    "\n",
    "**ğŸ¯ Estructura de Archivos de Salida:**\n",
    "\n",
    "1. **Datasets de entrenamiento/validaciÃ³n**:\n",
    "   - `train_native.csv` - Para Random Forest, LightGBM, CatBoost\n",
    "   - `val_native.csv` - ValidaciÃ³n versiÃ³n nativa\n",
    "   - `train_encoded.csv` - Para XGBoost\n",
    "   - `val_encoded.csv` - ValidaciÃ³n versiÃ³n codificada\n",
    "\n",
    "2. **Dataset de prueba procesado**:\n",
    "   - `test_native.csv` - Test versiÃ³n nativa\n",
    "   - `test_encoded.csv` - Test versiÃ³n codificada\n",
    "\n",
    "3. **Metadatos y informaciÃ³n**:\n",
    "   - `feature_info.json` - InformaciÃ³n de features por tipo\n",
    "   - `preprocessing_info.json` - Metadatos del preprocesamiento\n",
    "\n",
    "**ğŸ“ Directorio de salida:** `../data/processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DivisiÃ³n de datos para ambas versiones (Native y Encoded)\n",
    "print(\"=== DIVISIÃ“N DE DATOS PARA AMBAS VERSIONES ===\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# FunciÃ³n para crear split estratificado\n",
    "def create_train_val_split(X, y, test_size=0.2, random_state=513):\n",
    "    \"\"\"\n",
    "    Crea split estratificado manteniendo proporciÃ³n de clases\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, \n",
    "                           stratify=y, random_state=random_state)\n",
    "\n",
    "# Target variable (usar la columna target numÃ©rica)\n",
    "y = train_native['target']  # Target ya codificado\n",
    "\n",
    "print(f\"ğŸ“Š InformaciÃ³n del target:\")\n",
    "print(f\"  â€¢ Total muestras: {len(y):,}\")\n",
    "print(f\"  â€¢ Clases Ãºnicas: {y.nunique()}\")\n",
    "print(f\"  â€¢ Rango de clases: 0 a {y.max()}\")\n",
    "\n",
    "# ========================================\n",
    "# 1. DIVISIÃ“N PARA VERSIÃ“N NATIVE (RF, LightGBM, CatBoost)\n",
    "# ========================================\n",
    "print(f\"\\n1ï¸âƒ£ DivisiÃ³n para NATIVE version:\")\n",
    "\n",
    "# Features para versiÃ³n native (excluir columnas target y auxiliares)\n",
    "exclude_cols_native = ['Fertilizer Name', 'target', 'id'] if 'id' in train_native.columns else ['Fertilizer Name', 'target']\n",
    "features_native = [col for col in train_native.columns if col not in exclude_cols_native]\n",
    "X_native = train_native[features_native]\n",
    "y_native = y\n",
    "\n",
    "# Split estratificado para native\n",
    "X_train_native, X_val_native, y_train, y_val = create_train_val_split(X_native, y_native)\n",
    "\n",
    "print(f\"  ğŸ“Š X_train_native: {X_train_native.shape}\")\n",
    "print(f\"  ğŸ“Š X_val_native: {X_val_native.shape}\")\n",
    "print(f\"  ğŸ“Š y_train: {len(y_train)}\")\n",
    "print(f\"  ğŸ“Š y_val: {len(y_val)}\")\n",
    "\n",
    "# Preparar test native - mantener ID si existe\n",
    "if 'id' in test_native.columns:\n",
    "    # Conservar ID para las predicciones\n",
    "    test_ids = test_native['id']\n",
    "    features_test_native = [col for col in features_native if col in test_native.columns]\n",
    "    X_test_native = test_native[features_test_native]\n",
    "else:\n",
    "    # Si no hay columna id, crear una\n",
    "    test_ids = pd.Series(range(len(test_native)), name='id')\n",
    "    features_test_native = [col for col in features_native if col in test_native.columns]\n",
    "    X_test_native = test_native[features_test_native]\n",
    "\n",
    "print(f\"  ğŸ“Š X_test_native: {X_test_native.shape}\")\n",
    "\n",
    "# ========================================\n",
    "# 2. DIVISIÃ“N PARA VERSIÃ“N ENCODED (XGBoost)\n",
    "# ========================================\n",
    "print(f\"\\n2ï¸âƒ£ DivisiÃ³n para ENCODED version:\")\n",
    "\n",
    "# Features para versiÃ³n encoded (excluir columnas target y auxiliares)\n",
    "exclude_cols_encoded = ['Fertilizer Name', 'target', 'id'] if 'id' in train_encoded.columns else ['Fertilizer Name', 'target']\n",
    "# TambiÃ©n excluir las columnas categÃ³ricas originales (usar solo las _encoded)\n",
    "original_categoricals = ['Soil Type', 'Crop Type', 'Temp_Category', 'N_Level', 'P_Level', 'K_Level', 'Soil_Crop_Combo', 'NPK_Level_Combo']\n",
    "exclude_cols_encoded.extend(original_categoricals)\n",
    "\n",
    "features_encoded = [col for col in train_encoded.columns if col not in exclude_cols_encoded]\n",
    "X_encoded = train_encoded[features_encoded]\n",
    "y_encoded = train_encoded['target']  # Usar la columna target\n",
    "\n",
    "# Split estratificado para encoded (usando mismos Ã­ndices que native)\n",
    "X_train_encoded = X_encoded.iloc[X_train_native.index]\n",
    "X_val_encoded = X_encoded.iloc[X_val_native.index]\n",
    "\n",
    "print(f\"  ğŸ“Š X_train_encoded: {X_train_encoded.shape}\")\n",
    "print(f\"  ğŸ“Š X_val_encoded: {X_val_encoded.shape}\")\n",
    "\n",
    "# Preparar test encoded\n",
    "features_test_encoded = [col for col in features_encoded if col in test_encoded.columns]\n",
    "X_test_encoded = test_encoded[features_test_encoded]\n",
    "print(f\"  ğŸ“Š X_test_encoded: {X_test_encoded.shape}\")\n",
    "\n",
    "# ========================================\n",
    "# 3. VERIFICACIÃ“N DE ESTRATIFICACIÃ“N\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“Š VERIFICACIÃ“N DE ESTRATIFICACIÃ“N:\")\n",
    "print(f\"  Original: {y.value_counts().head(5).values}\")\n",
    "print(f\"  Train:    {y_train.value_counts().head(5).values}\")\n",
    "print(f\"  Val:      {y_val.value_counts().head(5).values}\")\n",
    "\n",
    "# Calcular proporciones\n",
    "train_prop = len(y_train) / len(y)\n",
    "val_prop = len(y_val) / len(y)\n",
    "print(f\"\\n  Proporciones: Train {train_prop:.1%}, Val {val_prop:.1%}\")\n",
    "\n",
    "# ========================================\n",
    "# 4. RESUMEN DE DATASETS PREPARADOS\n",
    "# ========================================\n",
    "print(f\"\\nğŸ¯ RESUMEN DE DATASETS PREPARADOS:\")\n",
    "print(f\"  â€¢ X_train_native: {X_train_native.shape} - Para Random Forest, LightGBM, CatBoost\")\n",
    "print(f\"  â€¢ X_val_native: {X_val_native.shape}\")\n",
    "print(f\"  â€¢ X_test_native: {X_test_native.shape}\")\n",
    "print(f\"  â€¢ X_train_encoded: {X_train_encoded.shape} - Para XGBoost\")\n",
    "print(f\"  â€¢ X_val_encoded: {X_val_encoded.shape}\")\n",
    "print(f\"  â€¢ X_test_encoded: {X_test_encoded.shape}\")\n",
    "print(f\"  â€¢ y_train, y_val: {len(y_train)}, {len(y_val)} muestras\")\n",
    "print(f\"  â€¢ test_ids: {len(test_ids)} IDs guardados\")\n",
    "\n",
    "print(f\"\\nğŸ“Š FEATURES DISPONIBLES:\")\n",
    "print(f\"  â€¢ Native features: {len(features_native)}\")\n",
    "print(f\"  â€¢ Encoded features: {len(features_encoded)}\")\n",
    "print(f\"  â€¢ CategÃ³ricas nativas: {len([f for f in features_native if f in original_categoricals])}\")\n",
    "print(f\"  â€¢ CategÃ³ricas codificadas: {len([f for f in features_encoded if '_encoded' in f])}\")\n",
    "\n",
    "print(f\"\\nâœ… DIVISIÃ“N DE DATOS COMPLETADA\")\n",
    "print(f\"  ğŸ¯ Dos versiones de datos preparadas para diferentes modelos\")\n",
    "print(f\"  ğŸ¯ EstratificaciÃ³n mantenida para ambas versiones\")\n",
    "print(f\"  ğŸ¯ Listos para entrenamiento y exportaciÃ³n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de datasets preprocesados para ambas versiones\n",
    "print(\"=== GUARDADO DE DATASETS PREPROCESADOS ===\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear directorio de salida\n",
    "output_dir = '../data/processed'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"ğŸ“ Directorio de salida: {output_dir}\")\n",
    "\n",
    "# FunciÃ³n para guardar datasets con informaciÃ³n adicional\n",
    "def save_processed_data(data, filename, description):\n",
    "    \"\"\"\n",
    "    Guarda un dataset con metadata\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    data.to_csv(filepath, index=False)\n",
    "    print(f\"  âœ… {filename}: {data.shape} - {description}\")\n",
    "    return filepath\n",
    "\n",
    "print(f\"\\nğŸ’¾ Guardando datasets procesados...\")\n",
    "\n",
    "# ========================================\n",
    "# 1. DATASETS VERSIÃ“N NATIVE (RF, LightGBM, CatBoost)\n",
    "# ========================================\n",
    "print(f\"\\n1ï¸âƒ£ Datasets NATIVE (Random Forest, LightGBM, CatBoost):\")\n",
    "\n",
    "# Combinar features y target para entrenamiento native\n",
    "train_data_native = X_train_native.copy()\n",
    "train_data_native['Fertilizer Name'] = train_native.loc[X_train_native.index, 'Fertilizer Name']\n",
    "train_data_native['target'] = y_train\n",
    "\n",
    "val_data_native = X_val_native.copy()\n",
    "val_data_native['Fertilizer Name'] = train_native.loc[X_val_native.index, 'Fertilizer Name']\n",
    "val_data_native['target'] = y_val\n",
    "\n",
    "# Test native con IDs\n",
    "test_data_native = X_test_native.copy()\n",
    "test_data_native['id'] = test_ids\n",
    "\n",
    "# Guardar datasets native\n",
    "save_processed_data(train_data_native, 'train_native.csv', \n",
    "                   'Training data NATIVE - categÃ³ricas como strings (RF, LightGBM, CatBoost)')\n",
    "save_processed_data(val_data_native, 'val_native.csv', \n",
    "                   'Validation data NATIVE')\n",
    "save_processed_data(test_data_native, 'test_native.csv', \n",
    "                   'Test data NATIVE')\n",
    "\n",
    "# ========================================\n",
    "# 2. DATASETS VERSIÃ“N ENCODED (XGBoost)\n",
    "# ========================================\n",
    "print(f\"\\n2ï¸âƒ£ Datasets ENCODED (XGBoost):\")\n",
    "\n",
    "# Combinar features y target para entrenamiento encoded\n",
    "train_data_encoded = X_train_encoded.copy()\n",
    "train_data_encoded['target'] = y_train\n",
    "\n",
    "val_data_encoded = X_val_encoded.copy()\n",
    "val_data_encoded['target'] = y_val\n",
    "\n",
    "# Test encoded con IDs\n",
    "test_data_encoded = X_test_encoded.copy()\n",
    "test_data_encoded['id'] = test_ids\n",
    "\n",
    "# Guardar datasets encoded\n",
    "save_processed_data(train_data_encoded, 'train_encoded.csv', \n",
    "                   'Training data ENCODED - categÃ³ricas codificadas (XGBoost)')\n",
    "save_processed_data(val_data_encoded, 'val_encoded.csv', \n",
    "                   'Validation data ENCODED')\n",
    "save_processed_data(test_data_encoded, 'test_encoded.csv', \n",
    "                   'Test data ENCODED')\n",
    "\n",
    "# ========================================\n",
    "# 3. METADATA Y INFORMACIÃ“N DE FEATURES\n",
    "# ========================================\n",
    "print(f\"\\n3ï¸âƒ£ Guardando metadata:\")\n",
    "\n",
    "# Obtener nombres de fertilizantes Ãºnicos para el mapeo\n",
    "fertilizer_names = sorted(train_native['Fertilizer Name'].unique())\n",
    "fertilizer_mapping = {i: name for i, name in enumerate(fertilizer_names)}\n",
    "\n",
    "# InformaciÃ³n de features\n",
    "feature_info = {\n",
    "    'features_native': {\n",
    "        'names': features_native,\n",
    "        'count': len(features_native),\n",
    "        'categorical': [col for col in features_native if col in ['Soil Type', 'Crop Type', 'Temp_Category', 'N_Level', 'P_Level', 'K_Level', 'Soil_Crop_Combo', 'NPK_Level_Combo']],\n",
    "        'numerical': [col for col in features_native if col not in ['Soil Type', 'Crop Type', 'Temp_Category', 'N_Level', 'P_Level', 'K_Level', 'Soil_Crop_Combo', 'NPK_Level_Combo']]\n",
    "    },\n",
    "    'features_encoded': {\n",
    "        'names': features_encoded,\n",
    "        'count': len(features_encoded),\n",
    "        'categorical_encoded': [col for col in features_encoded if '_encoded' in col],\n",
    "        'numerical': [col for col in features_encoded if '_encoded' not in col]\n",
    "    },\n",
    "    'target_info': {\n",
    "        'name': 'Fertilizer Name',\n",
    "        'classes': len(fertilizer_names),\n",
    "        'class_names': fertilizer_names,\n",
    "        'target_mapping': fertilizer_mapping\n",
    "    },\n",
    "    'split_info': {\n",
    "        'train_size': len(y_train),\n",
    "        'val_size': len(y_val),\n",
    "        'test_size': len(X_test_native),\n",
    "        'train_ratio': len(y_train) / len(y),\n",
    "        'val_ratio': len(y_val) / len(y)\n",
    "    },\n",
    "    'feature_counts': {\n",
    "        'native_total': len(features_native),\n",
    "        'encoded_total': len(features_encoded),\n",
    "        'categorical_native': len([f for f in features_native if f in ['Soil Type', 'Crop Type', 'Temp_Category', 'N_Level', 'P_Level', 'K_Level', 'Soil_Crop_Combo', 'NPK_Level_Combo']]),\n",
    "        'categorical_encoded': len([f for f in features_encoded if '_encoded' in f])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar informaciÃ³n de features\n",
    "with open(os.path.join(output_dir, 'feature_info.json'), 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "print(f\"  âœ… feature_info.json: InformaciÃ³n detallada de features\")\n",
    "\n",
    "# InformaciÃ³n de preprocesamiento\n",
    "preprocessing_info = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'original_data_shape': {\n",
    "        'train': list(train_df.shape),\n",
    "        'test': list(test_df.shape)\n",
    "    },\n",
    "    'processed_data_shape': {\n",
    "        'train_native': list(train_data_native.shape),\n",
    "        'val_native': list(val_data_native.shape),\n",
    "        'test_native': list(test_data_native.shape),\n",
    "        'train_encoded': list(train_data_encoded.shape),\n",
    "        'val_encoded': list(val_data_encoded.shape),\n",
    "        'test_encoded': list(test_data_encoded.shape)\n",
    "    },\n",
    "    'feature_engineering': {\n",
    "        'ratio_features': ['N_P_ratio', 'N_K_ratio', 'P_K_ratio'],\n",
    "        'categorical_features': ['N_Level', 'P_Level', 'K_Level', 'Temp_Category'],\n",
    "        'interaction_features': ['Soil_Crop_Combo', 'NPK_Level_Combo'],\n",
    "        'aggregate_features': ['Total_NPK', 'Environmental_Stress']\n",
    "    },\n",
    "    'encoding_strategy': {\n",
    "        'native_version': 'Categorical variables as strings for RF, LightGBM, CatBoost',\n",
    "        'encoded_version': 'LabelEncoder applied for XGBoost compatibility'\n",
    "    },\n",
    "    'files_created': {\n",
    "        'native': ['train_native.csv', 'val_native.csv', 'test_native.csv'],\n",
    "        'encoded': ['train_encoded.csv', 'val_encoded.csv', 'test_encoded.csv'],\n",
    "        'metadata': ['feature_info.json', 'preprocessing_info.json']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar informaciÃ³n de preprocesamiento\n",
    "with open(os.path.join(output_dir, 'preprocessing_info.json'), 'w') as f:\n",
    "    json.dump(preprocessing_info, f, indent=2)\n",
    "print(f\"  âœ… preprocessing_info.json: Metadata completa del preprocesamiento\")\n",
    "\n",
    "# ========================================\n",
    "# 4. RESUMEN FINAL\n",
    "# ========================================\n",
    "print(f\"\\nğŸ† RESUMEN FINAL DEL PREPROCESAMIENTO:\")\n",
    "print(f\"  ğŸ“ Archivos guardados en: {output_dir}\")\n",
    "print(f\"  ğŸ“Š Total de archivos generados: 8 datasets + 2 metadata\")\n",
    "print(f\"  ğŸ¯ Datasets NATIVE listos para: Random Forest, LightGBM, CatBoost\")\n",
    "print(f\"  ğŸ¯ Datasets ENCODED listos para: XGBoost\")\n",
    "print(f\"  ğŸ”„ Features engineered: {len(features_native)} total\")\n",
    "print(f\"  ğŸ¯ Target classes: {len(fertilizer_names)} fertilizantes\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ESTADÃSTICAS FINALES:\")\n",
    "print(f\"  â€¢ Train: {len(y_train):,} muestras\")\n",
    "print(f\"  â€¢ Validation: {len(y_val):,} muestras\")\n",
    "print(f\"  â€¢ Test: {len(test_ids):,} muestras\")\n",
    "print(f\"  â€¢ Features NATIVE: {len(features_native)}\")\n",
    "print(f\"  â€¢ Features ENCODED: {len(features_encoded)}\")\n",
    "\n",
    "print(f\"\\nâœ… Â¡PREPROCESAMIENTO COMPLETADO CON Ã‰XITO!\")\n",
    "print(f\"  ğŸš€ Listos para entrenar modelos baseline\")\n",
    "print(f\"  ğŸ¯ Siguiente paso: Crear notebooks de modelado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2babc52",
   "metadata": {},
   "source": [
    "## ğŸ¤” Estrategia de Encoding por Modelo\n",
    "\n",
    "### ğŸ“Š **Â¿Codificar Variables CategÃ³ricas para Tree-Based Models?**\n",
    "\n",
    "**La respuesta depende del modelo especÃ­fico:**\n",
    "\n",
    "| Modelo | Encoding Necesario | Estrategia Ã“ptima |\n",
    "|--------|-------------------|-------------------|\n",
    "| **Random Forest** | âŒ NO | Mantener categÃ³ricas como strings |\n",
    "| **XGBoost** | âœ… SÃ | LabelEncoder obligatorio |\n",
    "| **LightGBM** | ğŸ”„ OPCIONAL | CategÃ³ricas nativas (mejor) |\n",
    "| **CatBoost** | âŒ NO | CategÃ³ricas nativas con cat_features |\n",
    "\n",
    "### ğŸ¯ **Nuestra Estrategia Multi-Modelo:**\n",
    "\n",
    "1. **VersiÃ³n Native**: Variables categÃ³ricas como strings (RF, LightGBM, CatBoost)\n",
    "2. **VersiÃ³n Encoded**: LabelEncoder aplicado (XGBoost)\n",
    "3. **Features numÃ©ricas**: Sin escalar para todos los tree-based models\n",
    "\n",
    "**ğŸ’¡ Ventajas de categÃ³ricas nativas:**\n",
    "- Mejor manejo de alta cardinalidad (Soil_Crop_Combo: 110+ categorÃ­as)\n",
    "- Splits mÃ¡s inteligentes\n",
    "- Mejor interpretabilidad\n",
    "- Menos overfitting en high cardinality features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
