{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6741c5",
   "metadata": {},
   "source": [
    "# Modelado TIER 2: LightGBM\n",
    "\n",
    "Este notebook se enfoca en entrenar y evaluar un modelo LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d6b87",
   "metadata": {},
   "source": [
    "## 1. Carga de Librerías y Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c53c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Rutas de los datos preprocesados\n",
    "X_train_path = '../data/processed/X_train.parquet'\n",
    "y_train_path = '../data/processed/y_train.parquet'\n",
    "X_val_path = '../data/processed/X_val.parquet'\n",
    "y_val_path = '../data/processed/y_val.parquet'\n",
    "X_test_path = '../data/processed/X_test.parquet'\n",
    "feature_info_path = '../data/processed/feature_info.pkl'\n",
    "\n",
    "# Cargar los datos\n",
    "X_train = pd.read_parquet(X_train_path)\n",
    "y_train = pd.read_parquet(y_train_path).squeeze()\n",
    "X_val = pd.read_parquet(X_val_path)\n",
    "y_val = pd.read_parquet(y_val_path).squeeze()\n",
    "X_test = pd.read_parquet(X_test_path)\n",
    "\n",
    "# Cargar información de las características\n",
    "with open(feature_info_path, 'rb') as f:\n",
    "    feature_info = pickle.load(f)\n",
    "\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de X_val:\", X_val.shape)\n",
    "print(\"Forma de y_val:\", y_val.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Características seleccionadas:\", feature_info['selected_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7566d6",
   "metadata": {},
   "source": [
    "## 2. Definición y Entrenamiento del Modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets para LightGBM\n",
    "lgb_train = lgb.Dataset(X_train[feature_info['selected_features']], y_train)\n",
    "lgb_eval = lgb.Dataset(X_val[feature_info['selected_features']], y_val, reference=lgb_train)\n",
    "\n",
    "# Parámetros de LightGBM (puedes ajustarlos o usar Optuna/GridSearch para optimizarlos)\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'is_unbalance': True # Similar a class_weight='balanced'\n",
    "}\n",
    "\n",
    "print(\"Entrenando el modelo LightGBM...\")\n",
    "lgbm_model = lgb.train(params,\n",
    "                       lgb_train,\n",
    "                       num_boost_round=1000, # Número de iteraciones de boosting\n",
    "                       valid_sets=[lgb_train, lgb_eval],\n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True)])\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e5fc6",
   "metadata": {},
   "source": [
    "## 3. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en el conjunto de validación\n",
    "y_pred_proba_val = lgbm_model.predict(X_val[feature_info['selected_features']], num_iteration=lgbm_model.best_iteration)\n",
    "y_pred_val = (y_pred_proba_val > 0.5).astype(int) # Umbral de 0.5 para clasificación binaria\n",
    "\n",
    "# Calcular AUC-ROC\n",
    "auc_roc = roc_auc_score(y_val, y_pred_proba_val)\n",
    "print(f\"AUC-ROC en el conjunto de validación: {auc_roc:.4f}\")\n",
    "\n",
    "# Mostrar reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Mostrar matriz de confusión\n",
    "print(\"\\nMatriz de Confusión en el conjunto de validación:\")\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión - LightGBM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d46ef6",
   "metadata": {},
   "source": [
    "## 4. Importancia de las Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1755cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgbm_model, max_num_features=20, figsize=(10,8))\n",
    "plt.title('Importancia de las Características - LightGBM')\n",
    "plt.show()\n",
    "\n",
    "# Obtener y mostrar como DataFrame\n",
    "feature_importances = lgbm_model.feature_importance(importance_type='gain') # 'split' o 'gain'\n",
    "feature_names = X_train[feature_info['selected_features']].columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748d0b6",
   "metadata": {},
   "source": [
    "## 5. Guardar el Modelo (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0613e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_path = '../models/lightgbm_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(lgbm_model, f)\n",
    "print(f\"Modelo LightGBM guardado en: {model_path}\")\n",
    "\n",
    "# También podrías guardar las predicciones si es necesario para una submission\n",
    "# y_pred_test_proba = lgbm_model.predict(X_test[feature_info['selected_features']], num_iteration=lgbm_model.best_iteration)\n",
    "# submission_df = pd.read_csv('../data/sample_submission.csv')\n",
    "# submission_df['Exited'] = y_pred_test_proba\n",
    "# submission_df.to_csv('../submissions/submission_lgbm.csv', index=False)\n",
    "# print(\"Archivo de submission generado: ../submissions/submission_lgbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_path = '../models/lightgbm_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(lgbm_model, f)\n",
    "print(f\"Modelo LightGBM guardado en: {model_path}\")\n",
    "\n",
    "# También podrías guardar las predicciones si es necesario para una submission\n",
    "# y_pred_test_proba = lgbm_model.predict(X_test[feature_info['selected_features']], num_iteration=lgbm_model.best_iteration)\n",
    "# submission_df = pd.read_csv('../data/sample_submission.csv')\n",
    "# submission_df['Exited'] = y_pred_test_proba\n",
    "# submission_df.to_csv('../submissions/submission_lgbm.csv', index=False)\n",
    "# print(\"Archivo de submission generado: ../submissions/submission_lgbm.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
