{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7aca42",
   "metadata": {},
   "source": [
    "# üöÄ CatBoost con 10-Fold Cross-Validation - Predicci√≥n de Fertilizantes\n",
    "\n",
    "> **Objetivo**: Combinar la importaci√≥n de datos del modelado TIER 1 con validaci√≥n cruzada robusta de 10-fold para predecir **nombres de fertilizantes** optimizando MAP@3.\n",
    "> \n",
    "> **Variable Objetivo**: `Fertilizer Name` (nombres de fertilizantes codificados)\n",
    "> \n",
    "> **Estrategia**: Usar ModelTrainer para cargar datos preprocesados y aplicar 10-fold CV con CatBoost optimizado\n",
    "> \n",
    "> **M√©trica Principal**: MAP@3 (Mean Average Precision at 3) - requerida por la competencia de Kaggle\n",
    "> \n",
    "> **Mejoras**: Configuraci√≥n corregida de early stopping y ensemble de modelos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95c039",
   "metadata": {},
   "source": [
    "## üìö 1. Importar Librer√≠as y Datos\n",
    "\n",
    "### Importaci√≥n de librer√≠as necesarias y carga de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a78d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Utilidades del proyecto\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from model_utils import ModelTrainer, print_feature_selection_summary, print_training_config\n",
    "from visuals import plot_confusion_matrix, plot_feature_importance\n",
    "from metrics import mapk\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Configuraci√≥n\n",
    "np.random.seed(513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar trainer y cargar datos preprocesados\n",
    "trainer = ModelTrainer('CatBoostClassifier', 'CAT')\n",
    "data = trainer.load_data()\n",
    "\n",
    "# Extraer datasets\n",
    "X_train, y_train = data['X_train'], data['y_train']\n",
    "X_val, y_val = data['X_val'], data['y_val']\n",
    "X_test = data['X_test']\n",
    "feature_info = data['feature_info']\n",
    "label_encoders = data['label_encoders']\n",
    "fertilizer_encoder = label_encoders['Fertilizer Name']\n",
    "\n",
    "print(\"üìä Datos cargados exitosamente:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_val shape: {X_val.shape}\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ Variable objetivo: {y_train.name}\")\n",
    "print(f\"  ‚Ä¢ Clases objetivo: {len(fertilizer_encoder.classes_)}\")\n",
    "\n",
    "# Mostrar las clases de fertilizantes\n",
    "print(f\"\\nüß™ CLASES DE FERTILIZANTES:\")\n",
    "for i, class_name in enumerate(fertilizer_encoder.classes_):\n",
    "    print(f\"  {i}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b4c6e",
   "metadata": {},
   "source": [
    "## üéØ 2. Selecci√≥n de Features\n",
    "\n",
    "### Definiendo las caracter√≠sticas que utilizaremos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECCI√ìN DE FEATURES PARA EL MODELO\n",
    "# =============================================================================\n",
    "\n",
    "features_to_use = [\n",
    "    # üå°Ô∏è VARIABLES CLIM√ÅTICAS ORIGINALES\n",
    "    'Temparature',\n",
    "    'Humidity', \n",
    "    'Moisture',\n",
    "    \n",
    "    # üå± VARIABLES DE SUELO Y CULTIVO (CODIFICADAS)\n",
    "    # NOTA: CatBoost puede usar categ√≥ricas directamente como strings\n",
    "    # pero para mayor compatibilidad usamos las versiones codificadas\n",
    "    'Soil Type',     # ‚ùå Categ√≥rica sin codificar (requiere cat_features)\n",
    "    'Crop Type',     # ‚ùå Categ√≥rica sin codificar (requiere cat_features)\n",
    "\n",
    "    # üß™ VARIABLES QU√çMICAS (NPK)\n",
    "    'Nitrogen',\n",
    "    'Potassium', \n",
    "    'Phosphorous',\n",
    "    \n",
    "    # üìä FEATURES ENGINEERED - RATIOS NPK\n",
    "    # 'N_P_ratio',\n",
    "    # 'N_K_ratio',\n",
    "    # 'P_K_ratio',\n",
    "    # 'Total_NPK',\n",
    "    \n",
    "    # üå°Ô∏è FEATURES ENGINEERED - √çNDICES CLIM√ÅTICOS\n",
    "    # 'Temp_Hum_index',\n",
    "    # 'Moist_Balance',\n",
    "    # 'Environ_Stress',\n",
    "    \n",
    "    # # üè∑Ô∏è FEATURES ENGINEERED - CATEGOR√çAS\n",
    "    # 'Temp_Cat',\n",
    "    # 'Hum_Cat',\n",
    "    # 'N_Level',\n",
    "    # 'K_Level',\n",
    "    # 'P_Level',\n",
    "\n",
    "    # üîó FEATURES ENGINEERED - COMBINACIONES\n",
    "    # 'Soil_Crop_Combo',\n",
    "    # 'NPK_Balance',\n",
    "    # 'Dominant_NPK_Level',\n",
    "    # 'Temp_Moist_inter',\n",
    "    \n",
    "    # üî¢ FEATURES ENCODED (CATEG√ìRICAS) - ‚úÖ HABILITADAS\n",
    "    # 'Soil Type_encoded',      # ‚úÖ Versi√≥n codificada de Soil Type\n",
    "    # 'Crop Type_encoded',      # ‚úÖ Versi√≥n codificada de Crop Type\n",
    "    # 'Temp_Cat_encoded',\n",
    "    # 'Hum_Cat_encoded',\n",
    "    # 'N_Level_encoded',\n",
    "    # 'K_Level_encoded',\n",
    "    # 'P_Level_encoded',\n",
    "    # 'Soil_Crop_Combo_encoded'\n",
    "]\n",
    "\n",
    "# Validar features disponibles\n",
    "features_to_use = trainer.validate_features(features_to_use, X_train)\n",
    "print_feature_selection_summary(features_to_use, features_to_use)\n",
    "\n",
    "print(f\"\\n‚úÖ Features seleccionadas: {len(features_to_use)}\")\n",
    "print(f\"üìä Dimensi√≥n final: {X_train[features_to_use].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DE CARACTER√çSTICAS CATEG√ìRICAS PARA CATBOOST\n",
    "# =============================================================================\n",
    "\n",
    "# Identificar caracter√≠sticas categ√≥ricas en los features seleccionados\n",
    "categorical_features = []\n",
    "categorical_feature_indices = []\n",
    "\n",
    "# Revisar qu√© features categ√≥ricas est√°n disponibles\n",
    "print(f\"üîç AN√ÅLISIS DE CARACTER√çSTICAS CATEG√ìRICAS:\")\n",
    "print(f\"Features seleccionadas: {features_to_use}\")\n",
    "\n",
    "# Buscar caracter√≠sticas categ√≥ricas sin codificar\n",
    "for i, feature in enumerate(features_to_use):\n",
    "    if feature in ['Soil Type', 'Crop Type']:\n",
    "        categorical_features.append(feature)\n",
    "        categorical_feature_indices.append(i)\n",
    "        print(f\"  ‚úÖ Categ√≥rica encontrada: {feature} (√≠ndice {i})\")\n",
    "    elif any(cat_name in feature for cat_name in ['_Cat', 'Level', 'Combo']) and '_encoded' not in feature:\n",
    "        categorical_features.append(feature)\n",
    "        categorical_feature_indices.append(i)\n",
    "        print(f\"  ‚úÖ Categ√≥rica engineered: {feature} (√≠ndice {i})\")\n",
    "\n",
    "# Si no hay caracter√≠sticas categ√≥ricas, usar lista vac√≠a\n",
    "if not categorical_features:\n",
    "    print(f\"  ‚ùå No se encontraron caracter√≠sticas categ√≥ricas nativas\")\n",
    "    print(f\"  üìä Todas las caracter√≠sticas ser√°n tratadas como num√©ricas\")\n",
    "    categorical_feature_indices = []\n",
    "else:\n",
    "    print(f\"  ‚úÖ Total caracter√≠sticas categ√≥ricas: {len(categorical_features)}\")\n",
    "    print(f\"  üìä √çndices: {categorical_feature_indices}\")\n",
    "\n",
    "# Configuraci√≥n final para CatBoost\n",
    "print(f\"\\n‚öôÔ∏è CONFIGURACI√ìN CATBOOST:\")\n",
    "print(f\"  ‚Ä¢ Features totales: {len(features_to_use)}\")\n",
    "print(f\"  ‚Ä¢ Features categ√≥ricas: {len(categorical_feature_indices)}\")\n",
    "print(f\"  ‚Ä¢ Features num√©ricas: {len(features_to_use) - len(categorical_feature_indices)}\")\n",
    "print(f\"  ‚Ä¢ cat_features parameter: {categorical_feature_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efc0db",
   "metadata": {},
   "source": [
    "## üîÑ 3. Configuraci√≥n de Validaci√≥n Cruzada\n",
    "\n",
    "### Configuraci√≥n de validaci√≥n cruzada estratificada con k-fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DE VALIDACI√ìN CRUZADA ESTRATIFICADA\n",
    "# =============================================================================\n",
    "\n",
    "# Combinar datos de entrenamiento y validaci√≥n para CV completa\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä DATOS COMBINADOS PARA CV:\")\n",
    "print(f\"  ‚Ä¢ X_full shape: {X_full.shape}\")\n",
    "print(f\"  ‚Ä¢ y_full shape: {y_full.shape}\")\n",
    "print(f\"  ‚Ä¢ Features a usar: {len(features_to_use)}\")\n",
    "\n",
    "# Par√°metros de CV\n",
    "N_SPLITS = 10  # 10-fold cross-validation\n",
    "RANDOM_STATE = 513\n",
    "SHUFFLE = True\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_SPLITS, \n",
    "    shuffle=SHUFFLE, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÑ CONFIGURACI√ìN DE VALIDACI√ìN CRUZADA:\")\n",
    "print(f\"  ‚Ä¢ N√∫mero de folds: {N_SPLITS}\")\n",
    "print(f\"  ‚Ä¢ Estratificada: S√≠ (mantiene proporci√≥n de clases)\")\n",
    "print(f\"  ‚Ä¢ Shuffle: {SHUFFLE}\")\n",
    "print(f\"  ‚Ä¢ Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033e3d3",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Configuraci√≥n de Hiperpar√°metros CatBoost\n",
    "\n",
    "### Definiendo los par√°metros optimizados del modelo CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DE HIPERPAR√ÅMETROS CATBOOST OPTIMIZADA\n",
    "# =============================================================================\n",
    "\n",
    "# Configuraci√≥n optimizada basada en an√°lisis previos\n",
    "catboost_params = {\n",
    "    # Par√°metros principales\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'iterations': 1500,\n",
    "    'learning_rate': 0.075,\n",
    "    \n",
    "    # Estructura del √°rbol\n",
    "    'depth': 7,\n",
    "    \n",
    "    # Regularizaci√≥n\n",
    "    'l2_leaf_reg': 0.81,\n",
    "    \n",
    "    # Muestreo - Bayesian bootstrap\n",
    "    'bootstrap_type': 'Bayesian',       # ‚Üê use Bayesian\n",
    "    'bagging_temperature': 0.34,       # ‚Üê valid only for Bayesian\n",
    "    'random_strength': 6.65,\n",
    "    \n",
    "    # Optimizaci√≥n\n",
    "    'task_type': 'CPU',\n",
    "    \n",
    "    # Early stopping\n",
    "    'early_stopping_rounds': 50,\n",
    "    'use_best_model': True,\n",
    "    \n",
    "    # NOTA: cat_features se especifica directamente en Pool() objects\n",
    "    # en lugar de en los par√°metros del clasificador\n",
    "}\n",
    "\n",
    "# Configuraci√≥n de early stopping\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "VERBOSE_EVAL = 200\n",
    "\n",
    "print(f\"‚öôÔ∏è CONFIGURACI√ìN CATBOOST: {N_SPLITS}-fold CV\")\n",
    "print(f\"  ‚Ä¢ Iterations: {catboost_params['iterations']} | Early stopping: {EARLY_STOPPING_ROUNDS}\")\n",
    "print(f\"  ‚Ä¢ Learning rate: {catboost_params['learning_rate']} | Max depth: {catboost_params['depth']}\")\n",
    "print(f\"  ‚Ä¢ Features categ√≥ricas: {len(categorical_feature_indices)} de {len(features_to_use)}\")\n",
    "print(f\"  ‚Ä¢ Features categ√≥ricas indices: {categorical_feature_indices}\")\n",
    "print(f\"  ‚Ä¢ Clases objetivo: {len(fertilizer_encoder.classes_)}\")\n",
    "print(f\"  ‚Ä¢ Loss function: {catboost_params['loss_function']}\")\n",
    "print(f\"  ‚Ä¢ Eval metric: {catboost_params['eval_metric']}\")\n",
    "print(f\"  ‚Ä¢ Bootstrap type: {catboost_params['bootstrap_type']}\")\n",
    "print(f\"  ‚Ä¢ Task type: {catboost_params['task_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8021993",
   "metadata": {},
   "source": [
    "## üöÄ 5. Entrenamiento del Modelo con Validaci√≥n Cruzada\n",
    "\n",
    "### Entrenamiento con 10-fold CV y ensemble de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8021993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTRENAMIENTO CON 10-FOLD CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üöÄ INICIANDO ENTRENAMIENTO CON {N_SPLITS}-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Inicializar variables para almacenar resultados\n",
    "fold_results = []\n",
    "oof_predictions = np.zeros((len(X_full), len(fertilizer_encoder.classes_)))\n",
    "feature_importance_folds = []\n",
    "trained_models = []\n",
    "\n",
    "# Calcular class weights globales para balance\n",
    "class_counts = Counter(y_full)\n",
    "max_count = max(class_counts.values())\n",
    "class_weights = {cls: max_count / count for cls, count in class_counts.items()}\n",
    "\n",
    "print(f\"‚öñÔ∏è CLASS WEIGHTS PARA BALANCE:\")\n",
    "for cls, weight in class_weights.items():\n",
    "    class_name = fertilizer_encoder.classes_[cls]\n",
    "    print(f\"  {cls} ({class_name:15}): {weight:.3f}\")\n",
    "\n",
    "# Tiempo de inicio\n",
    "start_time = time.time()\n",
    "\n",
    "# Entrenamiento por folds\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full[features_to_use], y_full), 1):\n",
    "    print(f\"\\n{'='*20} FOLD {fold}/{N_SPLITS} {'='*20}\")\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_train_fold = X_full[features_to_use].iloc[train_idx]\n",
    "    X_val_fold = X_full[features_to_use].iloc[val_idx]\n",
    "    y_train_fold = y_full.iloc[train_idx]\n",
    "    y_val_fold = y_full.iloc[val_idx]\n",
    "    \n",
    "    print(f\"üìä Train size: {len(X_train_fold):,} | Val size: {len(X_val_fold):,}\")\n",
    "    \n",
    "    # Calcular sample weights para este fold\n",
    "    fold_class_counts = Counter(y_train_fold)\n",
    "    fold_max_count = max(fold_class_counts.values())\n",
    "    sample_weights = y_train_fold.map(lambda cls: fold_max_count / fold_class_counts[cls])\n",
    "    \n",
    "    # Crear pools de CatBoost\n",
    "    train_pool = Pool(\n",
    "        data=X_train_fold,\n",
    "        label=y_train_fold,\n",
    "        weight=sample_weights,\n",
    "        cat_features=categorical_feature_indices  # Usar √≠ndices de features categ√≥ricas\n",
    "    )\n",
    "    \n",
    "    val_pool = Pool(\n",
    "        data=X_val_fold,\n",
    "        label=y_val_fold,\n",
    "        cat_features=categorical_feature_indices  # Usar √≠ndices de features categ√≥ricas\n",
    "    )\n",
    "    \n",
    "    # Inicializar modelo\n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        verbose=VERBOSE_EVAL if fold == 1 else 0  # Solo verbose en el primer fold\n",
    "    )\n",
    "    \n",
    "    # Predicciones\n",
    "    val_pred_proba = model.predict_proba(X_val_fold)\n",
    "    val_pred = model.predict(X_val_fold)\n",
    "    \n",
    "    # Guardar predicciones OOF\n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_val_fold, val_pred)\n",
    "    \n",
    "    # MAP@3\n",
    "    top3_preds = np.argsort(val_pred_proba, axis=1)[:, ::-1][:, :3]\n",
    "    map3_score = mapk(y_val_fold.tolist(), top3_preds.tolist(), k=3)\n",
    "    \n",
    "    # Guardar resultados del fold\n",
    "    fold_time = time.time() - fold_start_time\n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy,\n",
    "        'map3': map3_score,\n",
    "        'best_iteration': model.get_best_iteration(),\n",
    "        'training_time': fold_time\n",
    "    })\n",
    "    \n",
    "    # Guardar modelo e importancia\n",
    "    trained_models.append(model)\n",
    "    feature_importance_folds.append(model.get_feature_importance())\n",
    "    \n",
    "    print(f\"‚úÖ Fold {fold} completado:\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   MAP@3: {map3_score:.4f}\")\n",
    "\n",
    "# Tiempo total\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è ENTRENAMIENTO COMPLETADO en {total_time:.1f}s ({total_time/60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950498e",
   "metadata": {},
   "source": [
    "## üìä 6. Evaluaci√≥n del Modelo\n",
    "\n",
    "### An√°lisis completo de rendimiento y m√©tricas de validaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23071c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACI√ìN COMPLETA DE RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä RESULTADOS DE VALIDACI√ìN CRUZADA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "# Estad√≠sticas de accuracy\n",
    "accuracy_mean = results_df['accuracy'].mean()\n",
    "accuracy_std = results_df['accuracy'].std()\n",
    "accuracy_min = results_df['accuracy'].min()\n",
    "accuracy_max = results_df['accuracy'].max()\n",
    "\n",
    "# Estad√≠sticas de MAP@3\n",
    "map3_mean = results_df['map3'].mean()\n",
    "map3_std = results_df['map3'].std()\n",
    "map3_min = results_df['map3'].min()\n",
    "map3_max = results_df['map3'].max()\n",
    "\n",
    "# Resumen estad√≠stico\n",
    "print(f\"\\nüéØ M√âTRICAS FINALES:\")\n",
    "print(f\"  üìà Accuracy promedio: {accuracy_mean:.4f} ¬± {accuracy_std:.4f}\")\n",
    "print(f\"  üìà MAP@3 promedio:    {map3_mean:.4f} ¬± {map3_std:.4f}\")\n",
    "print(f\"  üìä Rango Accuracy:    [{accuracy_min:.4f}, {accuracy_max:.4f}]\")\n",
    "print(f\"  üìä Rango MAP@3:       [{map3_min:.4f}, {map3_max:.4f}]\")\n",
    "\n",
    "# Evaluaci√≥n de estabilidad\n",
    "accuracy_cv = accuracy_std / accuracy_mean\n",
    "map3_cv = map3_std / map3_mean\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE ESTABILIDAD:\")\n",
    "print(f\"  üìä Coeficiente de variaci√≥n (Accuracy): {accuracy_cv:.3f}\")\n",
    "print(f\"  üìä Coeficiente de variaci√≥n (MAP@3):    {map3_cv:.3f}\")\n",
    "print(f\"  {'‚úÖ Modelo estable' if accuracy_cv < 0.05 else '‚ö†Ô∏è Modelo variable'} (Accuracy CV < 0.05)\")\n",
    "print(f\"  {'‚úÖ Modelo estable' if map3_cv < 0.05 else '‚ö†Ô∏è Modelo variable'} (MAP@3 CV < 0.05)\")\n",
    "\n",
    "# Tiempo promedio por fold\n",
    "avg_fold_time = results_df['training_time'].mean()\n",
    "print(f\"\\n‚è±Ô∏è TIEMPOS DE ENTRENAMIENTO:\")\n",
    "print(f\"  üìä Tiempo promedio por fold: {avg_fold_time:.1f}s\")\n",
    "print(f\"  üìä Tiempo total: {total_time:.1f}s ({total_time/60:.1f}min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c331ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACI√ìN OUT-OF-FOLD (OOF)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç EVALUACI√ìN OUT-OF-FOLD (OOF)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Predicciones OOF finales\n",
    "oof_pred = np.argmax(oof_predictions, axis=1)\n",
    "oof_accuracy = accuracy_score(y_full, oof_pred)\n",
    "\n",
    "# MAP@3 con predicciones OOF\n",
    "oof_top3 = np.argsort(oof_predictions, axis=1)[:, ::-1][:, :3]\n",
    "oof_map3 = mapk(y_full.tolist(), oof_top3.tolist(), k=3)\n",
    "\n",
    "print(f\"üìä M√âTRICAS OOF (predicciones combinadas):\")\n",
    "print(f\"  üéØ OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "print(f\"  üéØ OOF MAP@3:    {oof_map3:.4f}\")\n",
    "\n",
    "# Comparaci√≥n con CV\n",
    "print(f\"\\nüìä COMPARACI√ìN CV vs OOF:\")\n",
    "print(f\"  Accuracy: CV={accuracy_mean:.4f} | OOF={oof_accuracy:.4f} | Diff={abs(accuracy_mean-oof_accuracy):.4f}\")\n",
    "print(f\"  MAP@3:    CV={map3_mean:.4f} | OOF={oof_map3:.4f} | Diff={abs(map3_mean-oof_map3):.4f}\")\n",
    "\n",
    "# M√©tricas por clase\n",
    "print(f\"\\nüìä M√âTRICAS POR CLASE (OOF):\")\n",
    "class_report = classification_report(y_full, oof_pred, \n",
    "                                   target_names=fertilizer_encoder.classes_,\n",
    "                                   output_dict=True)\n",
    "\n",
    "print(\"Clase            Precision  Recall  F1-Score  Support\")\n",
    "print(\"-\" * 55)\n",
    "for class_name in fertilizer_encoder.classes_:\n",
    "    metrics = class_report[class_name]\n",
    "    print(f\"{class_name:15} {metrics['precision']:8.3f} {metrics['recall']:7.3f} {metrics['f1-score']:8.3f} {metrics['support']:8.0f}\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "macro_avg = class_report['macro avg']\n",
    "print(f\"{'Macro avg':15} {macro_avg['precision']:8.3f} {macro_avg['recall']:7.3f} {macro_avg['f1-score']:8.3f} {macro_avg['support']:8.0f}\")\n",
    "weighted_avg = class_report['weighted avg']\n",
    "print(f\"{'Weighted avg':15} {weighted_avg['precision']:8.3f} {weighted_avg['recall']:7.3f} {weighted_avg['f1-score']:8.3f} {weighted_avg['support']:8.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calcular importancia promedio\n",
    "feature_importance_mean = np.mean(feature_importance_folds, axis=0)\n",
    "feature_importance_std = np.std(feature_importance_folds, axis=0)\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features_to_use,\n",
    "    'importance_mean': feature_importance_mean,\n",
    "    'importance_std': feature_importance_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "# An√°lisis de tipos de caracter√≠sticas\n",
    "print(f\"\\nüìä AN√ÅLISIS POR TIPO DE CARACTER√çSTICA:\")\n",
    "numeric_features = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "engineered_features = [f for f in features_to_use if any(keyword in f for keyword in ['ratio', 'index', 'Balance', 'Total', 'inter'])]\n",
    "encoded_features = [f for f in features_to_use if '_encoded' in f]\n",
    "\n",
    "numeric_importance = importance_df[importance_df['feature'].isin(numeric_features)]['importance_mean'].sum()\n",
    "engineered_importance = importance_df[importance_df['feature'].isin(engineered_features)]['importance_mean'].sum()\n",
    "encoded_importance = importance_df[importance_df['feature'].isin(encoded_features)]['importance_mean'].sum()\n",
    "total_importance = numeric_importance + engineered_importance + encoded_importance\n",
    "\n",
    "if total_importance > 0:\n",
    "    print(f\"  üî¢ Caracter√≠sticas num√©ricas:    {numeric_importance:.3f} ({numeric_importance/total_importance*100:.1f}%)\")\n",
    "    print(f\"  ‚öôÔ∏è Features engineered:         {engineered_importance:.3f} ({engineered_importance/total_importance*100:.1f}%)\")\n",
    "    print(f\"  üè∑Ô∏è Caracter√≠sticas categ√≥ricas: {encoded_importance:.3f} ({encoded_importance/total_importance*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f584364",
   "metadata": {},
   "source": [
    "## üéØ 7. Generaci√≥n de Predicciones para Test\n",
    "\n",
    "### Predicciones finales usando ensemble de 10 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERACI√ìN DE PREDICCIONES PARA TEST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ GENERANDO PREDICCIONES PARA CONJUNTO DE TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensemble de predicciones de todos los modelos\n",
    "print(f\"üìä Ensemble de {len(trained_models)} modelos entrenados...\")\n",
    "\n",
    "test_predictions_all = []\n",
    "for i, model in enumerate(trained_models):\n",
    "    pred_proba = model.predict_proba(X_test[features_to_use])\n",
    "    test_predictions_all.append(pred_proba)\n",
    "    if i < 3:  # Mostrar progreso para los primeros 3\n",
    "        print(f\"  ‚úÖ Modelo {i+1}: Predicciones generadas\")\n",
    "\n",
    "if len(trained_models) > 3:\n",
    "    print(f\"  ‚úÖ ... y {len(trained_models)-3} modelos m√°s\")\n",
    "\n",
    "# Promedio de las predicciones (ensemble)\n",
    "test_predictions_ensemble = np.mean(test_predictions_all, axis=0)\n",
    "print(f\"üìä Shape de predicciones ensemble: {test_predictions_ensemble.shape}\")\n",
    "\n",
    "# Obtener √≠ndices de las top 3 clases para cada muestra\n",
    "test_top3_indices = np.argsort(test_predictions_ensemble, axis=1)[:, ::-1][:, :3]\n",
    "print(f\"üìä Shape de top-3 √≠ndices: {test_top3_indices.shape}\")\n",
    "\n",
    "# Convertir √≠ndices a nombres de fertilizantes\n",
    "test_top3_names = []\n",
    "for i in range(len(test_top3_indices)):\n",
    "    top3_for_sample = []\n",
    "    for j in range(3):\n",
    "        class_idx = test_top3_indices[i, j]\n",
    "        class_name = fertilizer_encoder.classes_[class_idx]\n",
    "        top3_for_sample.append(class_name)\n",
    "    test_top3_names.append(top3_for_sample)\n",
    "\n",
    "print(f\"‚úÖ Conversi√≥n a nombres completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145a3d8",
   "metadata": {},
   "source": [
    "## üéâ 8. Resumen Final y Conclusiones\n",
    "\n",
    "### Resultados del modelo combinado con 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACI√ìN PARA GUARDADO DE ARCHIVOS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar nombre del modelo basado en MAP@3\n",
    "model_name = f\"CAT_10CV_MAP@3-{oof_map3:.5f}\".replace('.', '')\n",
    "model_dir = f\"../models/CAT/{N_SPLITS}CV/{model_name}\"\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ DIRECTORIO DEL MODELO:\")\n",
    "print(f\"  {model_dir}\")\n",
    "\n",
    "# Configuraci√≥n de nombres de archivos\n",
    "base_filename = model_name\n",
    "files_to_create = {\n",
    "    'hparams': f\"{base_filename}_hparams.json\",\n",
    "    'metrics': f\"{base_filename}_metrics.json\",\n",
    "    'metrics_pkl': f\"{base_filename}_metrics.pkl\",\n",
    "    'model_pkl': f\"{base_filename}_model.pkl\",\n",
    "    'feature_import': f\"{base_filename}_feature_importance.csv\",\n",
    "    'submission': f\"{base_filename}_submission.csv\",\n",
    "    'submission_info': f\"{base_filename}_submission_info.json\"\n",
    "}\n",
    "\n",
    "print(f\"\\nüìù ARCHIVOS A CREAR:\")\n",
    "for file_type, filename in files_to_create.items():\n",
    "    print(f\"  {file_type:15}: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69658702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR HIPERPAR√ÅMETROS\n",
    "# =============================================================================\n",
    "\n",
    "hparams_data = {\n",
    "    \"model_type\": \"CatBoostClassifier\",\n",
    "    \"model_abbreviation\": \"CAT\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \"ensemble_method\": \"Average of fold predictions\",\n",
    "    \"hyperparameters\": catboost_params,\n",
    "    \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "    \"features_selected\": features_to_use,\n",
    "    \"num_features\": len(features_to_use),\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"categorical_feature_indices\": categorical_feature_indices,\n",
    "    \"num_categorical_features\": len(categorical_feature_indices),\n",
    "    \"class_weights_used\": True,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"cv_splits\": N_SPLITS,\n",
    "    \"total_models\": len(trained_models)\n",
    "}\n",
    "\n",
    "# Guardar hiperpar√°metros\n",
    "hparams_file = os.path.join(model_dir, files_to_create['hparams'])\n",
    "with open(hparams_file, 'w') as f:\n",
    "    json.dump(hparams_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b10593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR M√âTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "# M√©tricas principales para JSON\n",
    "metrics_data = {\n",
    "    \"model_type\": \"CatBoostClassifier\",\n",
    "    \"model_abbreviation\": \"CAT\",\n",
    "    \"tier\": \"10_FOLD_CV\",\n",
    "    \"target_variable\": \"Fertilizer Name\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \n",
    "    # M√©tricas principales\n",
    "    \"map3_score_cv_mean\": float(map3_mean),\n",
    "    \"map3_score_cv_std\": float(map3_std),\n",
    "    \"map3_score_oof\": float(oof_map3),\n",
    "    \"accuracy_cv_mean\": float(accuracy_mean),\n",
    "    \"accuracy_cv_std\": float(accuracy_std),\n",
    "    \"accuracy_oof\": float(oof_accuracy),\n",
    "    \n",
    "    # Informaci√≥n del modelo\n",
    "    \"num_classes\": len(fertilizer_encoder.classes_),\n",
    "    \"features_used\": len(features_to_use),\n",
    "    \"features_list\": features_to_use,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"categorical_feature_indices\": categorical_feature_indices,\n",
    "    \"num_categorical_features\": len(categorical_feature_indices),\n",
    "    \"cv_folds\": N_SPLITS,\n",
    "    \"total_models_trained\": len(trained_models),\n",
    "    \n",
    "    # M√©tricas por fold\n",
    "    \"fold_results\": fold_results,\n",
    "    \n",
    "    # Estad√≠sticas de estabilidad\n",
    "    \"accuracy_cv_coefficient\": float(accuracy_cv),\n",
    "    \"map3_cv_coefficient\": float(map3_cv),\n",
    "    \n",
    "    # Tiempos\n",
    "    \"training_time_total\": float(total_time),\n",
    "    \"training_time_per_fold_avg\": float(avg_fold_time),\n",
    "    \n",
    "    # Metadatos\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"kaggle_competition\": \"playground-series-s5e6\"\n",
    "}\n",
    "\n",
    "# Guardar m√©tricas JSON\n",
    "metrics_file = os.path.join(model_dir, files_to_create['metrics'])\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "\n",
    "# M√©tricas completas para PKL (incluye objetos complejos)\n",
    "metrics_pkl_data = {\n",
    "    **metrics_data,\n",
    "    \"oof_predictions\": oof_predictions,\n",
    "    \"trained_models\": trained_models,\n",
    "    \"feature_importance_folds\": feature_importance_folds,\n",
    "    \"class_report\": class_report,\n",
    "    \"confusion_matrix\": confusion_matrix(y_full, oof_pred),\n",
    "    \"fertilizer_encoder\": fertilizer_encoder\n",
    "}\n",
    "\n",
    "# Guardar m√©tricas PKL\n",
    "metrics_pkl_file = os.path.join(model_dir, files_to_create['metrics_pkl'])\n",
    "joblib.dump(metrics_pkl_data, metrics_pkl_file, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c81ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR IMPORTANCIA DE CARACTER√çSTICAS\n",
    "# =============================================================================\n",
    "\n",
    "# Guardar DataFrame de importancia\n",
    "feature_importance_file = os.path.join(model_dir, files_to_create['feature_import'])\n",
    "importance_df.to_csv(feature_importance_file, index=False)\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR MODELOS ENTRENADOS\n",
    "# =============================================================================\n",
    "\n",
    "# Guardar el ensemble de modelos entrenados\n",
    "model_data = {\n",
    "    \"ensemble_models\": trained_models,\n",
    "    \"model_type\": \"CatBoostClassifier\",\n",
    "    \"cv_folds\": N_SPLITS,\n",
    "    \"features_used\": features_to_use,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"categorical_feature_indices\": categorical_feature_indices,\n",
    "    \"hyperparameters\": catboost_params,\n",
    "    \"label_encoder\": fertilizer_encoder,\n",
    "    \"training_info\": {\n",
    "        \"map3_cv_mean\": float(map3_mean),\n",
    "        \"map3_oof\": float(oof_map3),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar modelos\n",
    "model_file = os.path.join(model_dir, files_to_create['model_pkl'])\n",
    "joblib.dump(model_data, model_file, compress=3)\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR SUBMISSION Y INFORMACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "# Crear submission directamente desde predicciones del ensemble\n",
    "print(f\"üìù Creando submission desde ensemble de {len(trained_models)} modelos...\")\n",
    "\n",
    "# Formatear predicciones como string separado por espacios\n",
    "submission_predictions = []\n",
    "for top3_names in test_top3_names:\n",
    "    prediction_string = ' '.join(top3_names)\n",
    "    submission_predictions.append(prediction_string)\n",
    "\n",
    "# Crear DataFrame de submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test.index,  # Usar √≠ndice de X_test como ID\n",
    "    'Fertilizer Name': submission_predictions\n",
    "})\n",
    "\n",
    "# Guardar archivo de submission\n",
    "submission_file = os.path.join(model_dir, files_to_create['submission'])\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "# Informaci√≥n del submission\n",
    "submission_info = {\n",
    "    \"model_type\": \"CatBoostClassifier\",\n",
    "    \"model_abbreviation\": \"CAT\",\n",
    "    \"cv_strategy\": f\"{N_SPLITS}-Fold Stratified Cross Validation\",\n",
    "    \"map3_score_cv_mean\": float(map3_mean),\n",
    "    \"map3_score_oof\": float(oof_map3),\n",
    "    \"submission_file\": files_to_create['submission'],\n",
    "    \"num_predictions\": len(submission),\n",
    "    \"format\": \"MAP@3 - Top 3 fertilizer names separated by spaces\",\n",
    "    \"target_variable\": \"Fertilizer Name\",\n",
    "    \"ensemble_models\": len(trained_models),\n",
    "    \"features_used\": len(features_to_use),\n",
    "    \"total_training_time_minutes\": float(total_time / 60),\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"kaggle_competition\": \"playground-series-s5e6\"\n",
    "}\n",
    "\n",
    "# Guardar informaci√≥n del submission\n",
    "submission_info_file = os.path.join(model_dir, files_to_create['submission_info'])\n",
    "with open(submission_info_file, 'w') as f:\n",
    "    json.dump(submission_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RESUMEN FINAL DE ARCHIVOS GUARDADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüíæ RESUMEN FINAL - ARCHIVOS GUARDADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìÅ DIRECTORIO: {model_dir}\")\n",
    "print(f\"\\nüìÑ ARCHIVOS CREADOS:\")\n",
    "\n",
    "# Verificar y mostrar todos los archivos creados\n",
    "for file_type, filename in files_to_create.items():\n",
    "    file_path = os.path.join(model_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        if file_size > 1024*1024:  # > 1MB\n",
    "            size_str = f\"{file_size/(1024*1024):.1f} MB\"\n",
    "        elif file_size > 1024:  # > 1KB\n",
    "            size_str = f\"{file_size/1024:.1f} KB\"\n",
    "        else:\n",
    "            size_str = f\"{file_size} bytes\"\n",
    "        \n",
    "        print(f\"  ‚úÖ {filename:35} ({size_str})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {filename:35} (NO CREADO)\")\n",
    "\n",
    "print(f\"\\nüéØ M√âTRICAS PRINCIPALES:\")\n",
    "print(f\"  üìä MAP@3 (CV Mean): {map3_mean:.5f} ¬± {map3_std:.5f}\")\n",
    "print(f\"  üìä MAP@3 (OOF):     {oof_map3:.5f}\")\n",
    "print(f\"  üìä Accuracy (OOF):  {oof_accuracy:.5f}\")\n",
    "print(f\"  ü§ñ Modelos:         {len(trained_models)} (ensemble)\")\n",
    "print(f\"  üìä Features:        {len(features_to_use)}\")\n",
    "print(f\"  ‚è±Ô∏è Tiempo total:    {total_time/60:.1f} minutos\")\n",
    "\n",
    "print(f\"\\nüéâ TODOS LOS ARCHIVOS GUARDADOS EXITOSAMENTE\")\n",
    "print(f\"üìÇ Ubicaci√≥n: {os.path.abspath(model_dir)}\")\n",
    "\n",
    "print(f\"\\nüçÉ ENTRENAMIENTO CATBOOST COMPLETADO\")\n",
    "print(f\"  ‚Ä¢ Algoritmo: CatBoost con 10-fold cross-validation\")\n",
    "print(f\"  ‚Ä¢ MAP@3 objetivo: > 0.32\")\n",
    "print(f\"  ‚Ä¢ MAP@3 alcanzado: {oof_map3:.5f}\")\n",
    "print(f\"  ‚Ä¢ Estado: {'\\u2705 OBJETIVO ALCANZADO' if oof_map3 > 0.32 else 'üìà MEJORA NECESARIA'}\")\n",
    "print(f\"  ‚Ä¢ Archivos listos para ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
